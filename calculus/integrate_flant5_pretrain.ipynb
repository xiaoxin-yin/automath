{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8aab416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in datasets/amps/mathematica/algebra/complex_norm_and_arg\n",
      "Done with datasets/amps/mathematica/algebra/complex_norm_and_arg\n",
      "50000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/spherical_coordinates\n",
      "Done with datasets/amps/mathematica/algebra/spherical_coordinates\n",
      "100000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/complex_raised_to_exponent\n",
      "Done with datasets/amps/mathematica/algebra/complex_raised_to_exponent\n",
      "150000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/sqrt_equations_w_steps\n",
      "Done with datasets/amps/mathematica/algebra/sqrt_equations_w_steps\n",
      "155000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/multiply_polynomials\n",
      "Done with datasets/amps/mathematica/algebra/multiply_polynomials\n",
      "205000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/log_equations\n",
      "Done with datasets/amps/mathematica/algebra/log_equations\n",
      "255000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/factor_polynomials\n",
      "Done with datasets/amps/mathematica/algebra/factor_polynomials\n",
      "310000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/function_range\n",
      "Done with datasets/amps/mathematica/algebra/function_range\n",
      "320000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/parametric_equations\n",
      "Done with datasets/amps/mathematica/algebra/parametric_equations\n",
      "370000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/quadratic_roots_w_steps\n",
      "Done with datasets/amps/mathematica/algebra/quadratic_roots_w_steps\n",
      "375000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/factor_polynomials_w_steps\n",
      "Done with datasets/amps/mathematica/algebra/factor_polynomials_w_steps\n",
      "380000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/polynomial_gcd\n",
      "Done with datasets/amps/mathematica/algebra/polynomial_gcd\n",
      "430000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/quadratic_roots\n",
      "Done with datasets/amps/mathematica/algebra/quadratic_roots\n",
      "480000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/conic_sections\n",
      "Done with datasets/amps/mathematica/algebra/conic_sections\n",
      "530000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/multiply_polynomials_w_steps\n",
      "Done with datasets/amps/mathematica/algebra/multiply_polynomials_w_steps\n",
      "535000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/function_domain\n",
      "Done with datasets/amps/mathematica/algebra/function_domain\n",
      "545000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/system_of_equations_w_steps\n",
      "Done with datasets/amps/mathematica/algebra/system_of_equations_w_steps\n",
      "550000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/pemdas\n",
      "Done with datasets/amps/mathematica/algebra/pemdas\n",
      "600000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/arithmetic_series\n",
      "Done with datasets/amps/mathematica/algebra/arithmetic_series\n",
      "650000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/solve_abs_value_equation\n",
      "Done with datasets/amps/mathematica/algebra/solve_abs_value_equation\n",
      "700000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/polynomial_arithmetic\n",
      "Done with datasets/amps/mathematica/algebra/polynomial_arithmetic\n",
      "750000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/geometric_series\n",
      "Done with datasets/amps/mathematica/algebra/geometric_series\n",
      "800000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/polynomial_division_equation\n",
      "Done with datasets/amps/mathematica/algebra/polynomial_division_equation\n",
      "850000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/sqrt_equations\n",
      "Done with datasets/amps/mathematica/algebra/sqrt_equations\n",
      "900000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/exponential_equations\n",
      "Done with datasets/amps/mathematica/algebra/exponential_equations\n",
      "950000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/find_roots\n",
      "Done with datasets/amps/mathematica/algebra/find_roots\n",
      "960000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/complete_square\n",
      "Done with datasets/amps/mathematica/algebra/complete_square\n",
      "1010000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/complex_arithmetic\n",
      "Done with datasets/amps/mathematica/algebra/complex_arithmetic\n",
      "1060000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/polynomial_quotient\n",
      "Done with datasets/amps/mathematica/algebra/polynomial_quotient\n",
      "1110000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/simplify_radicals\n",
      "Done with datasets/amps/mathematica/algebra/simplify_radicals\n",
      "1120000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/simplify_radicals_w_steps\n",
      "Done with datasets/amps/mathematica/algebra/simplify_radicals_w_steps\n",
      "1125000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/function_evaluation\n",
      "Done with datasets/amps/mathematica/algebra/function_evaluation\n",
      "1175000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/system_of_equations\n",
      "Done with datasets/amps/mathematica/algebra/system_of_equations\n",
      "1225000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/invert_function\n",
      "Done with datasets/amps/mathematica/algebra/invert_function\n",
      "1235000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/complete_square_w_steps\n",
      "Done with datasets/amps/mathematica/algebra/complete_square_w_steps\n",
      "1240000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/divisible\n",
      "Done with datasets/amps/mathematica/number_theory/divisible\n",
      "1290000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/continued_fraction\n",
      "Done with datasets/amps/mathematica/number_theory/continued_fraction\n",
      "1340000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/relatively_prime\n",
      "Done with datasets/amps/mathematica/number_theory/relatively_prime\n",
      "1390000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/relatively_prime_w_steps\n",
      "Done with datasets/amps/mathematica/number_theory/relatively_prime_w_steps\n",
      "1395000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/gcd_w_steps\n",
      "Done with datasets/amps/mathematica/number_theory/gcd_w_steps\n",
      "1400000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/primitive_roots\n",
      "Done with datasets/amps/mathematica/number_theory/primitive_roots\n",
      "1410000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/factor_integer_w_steps\n",
      "Done with datasets/amps/mathematica/number_theory/factor_integer_w_steps\n",
      "1415000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/multiplicative_order\n",
      "Done with datasets/amps/mathematica/number_theory/multiplicative_order\n",
      "1465000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/totient_w_steps\n",
      "Done with datasets/amps/mathematica/number_theory/totient_w_steps\n",
      "1470000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/factor_integer\n",
      "Done with datasets/amps/mathematica/number_theory/factor_integer\n",
      "1480000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/convert_base\n",
      "Done with datasets/amps/mathematica/number_theory/convert_base\n",
      "1530000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/gcd\n",
      "Done with datasets/amps/mathematica/number_theory/gcd\n",
      "1580000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/polygonal_number\n",
      "Done with datasets/amps/mathematica/number_theory/polygonal_number\n",
      "1580500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/lcm_w_steps\n",
      "Done with datasets/amps/mathematica/number_theory/lcm_w_steps\n",
      "1585500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/lcm\n",
      "Done with datasets/amps/mathematica/number_theory/lcm\n",
      "1635500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/power_mod\n",
      "Done with datasets/amps/mathematica/number_theory/power_mod\n",
      "1685500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/mod\n",
      "Done with datasets/amps/mathematica/number_theory/mod\n",
      "1735500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/is_prime_w_steps\n",
      "Done with datasets/amps/mathematica/number_theory/is_prime_w_steps\n",
      "1750500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/totient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with datasets/amps/mathematica/number_theory/totient\n",
      "1800500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/diophantine_equations\n",
      "Done with datasets/amps/mathematica/number_theory/diophantine_equations\n",
      "1850500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/modular_inverse\n",
      "Done with datasets/amps/mathematica/number_theory/modular_inverse\n",
      "1900500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/chinese_remainder_theorem\n",
      "Done with datasets/amps/mathematica/number_theory/chinese_remainder_theorem\n",
      "1950500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/is_prime\n",
      "Done with datasets/amps/mathematica/number_theory/is_prime\n",
      "1980500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/convert_base_w_steps\n",
      "Done with datasets/amps/mathematica/number_theory/convert_base_w_steps\n",
      "1990500 files read\n"
     ]
    }
   ],
   "source": [
    "# Generate data to infer the rules for integral\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "from sympy import sympify, lambdify, symbols, integrate, Interval, Symbol, I, S, oo, plot, evalf, N\n",
    "from IPython.display import display\n",
    "from utils.utils import *\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "def split_problem_and_answer(s):\n",
    "    pos = s.find(\"Answer:\")\n",
    "    if pos < 0:\n",
    "        return None, None\n",
    "    return s[0:pos], s[pos:]\n",
    "\n",
    "parent_folder = 'datasets/amps/mathematica/algebra'\n",
    "for folder in os.listdir(parent_folder): \n",
    "    folder_path = os.path.join(parent_folder, folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    print(\"Loading files in\", folder_path)\n",
    "    for file in os.listdir(folder_path):\n",
    "        if not file.endswith('.txt'):\n",
    "            continue\n",
    "        filepath = os.path.join(folder_path, file)\n",
    "        fin = open(filepath, 'r')\n",
    "        lines = fin.readlines()\n",
    "        problem, answer = split_problem_and_answer(' '.join(lines))\n",
    "        questions.append(problem)\n",
    "        answers.append(answer)\n",
    "        fin.close()\n",
    "    print(\"Done with\", folder_path)\n",
    "    print(len(questions), \"files read\")\n",
    "    \n",
    "parent_folder = 'datasets/amps/mathematica/number_theory'\n",
    "for folder in os.listdir(parent_folder): \n",
    "    folder_path = os.path.join(parent_folder, folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    print(\"Loading files in\", folder_path)\n",
    "    for file in os.listdir(folder_path):\n",
    "        if not file.endswith('.txt'):\n",
    "            continue\n",
    "        filepath = os.path.join(folder_path, file)\n",
    "        fin = open(filepath, 'r')\n",
    "        lines = fin.readlines()\n",
    "        problem, answer = split_problem_and_answer(' '.join(lines))\n",
    "        questions.append(problem)\n",
    "        answers.append(answer)\n",
    "        fin.close()\n",
    "    print(\"Done with\", folder_path)\n",
    "    print(len(questions), \"files read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d12f7122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Problem:\\n If $x = \\\\frac{985}{27198}$, then find $\\\\frac{1}{x+\\\\frac{1}{x+\\\\frac{1}{x+\\\\ddots}}}$.\\n ',\n",
       " 'answer': 'Answer:\\n $\\\\frac{\\\\sqrt{2959895041}-985}{54396}$'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import random\n",
    "from datasets import load_dataset, Dataset, load_from_disk\n",
    "\n",
    "ds = Dataset.from_dict({'question': questions, 'answer':answers})\n",
    "ds = ds.shuffle()\n",
    "train_ds = ds.train_test_split(test_size=0.005)\n",
    "\n",
    "train_ds['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e7bd405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 1980547\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 9953\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de73e66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1980547/1980547 [04:38<00:00, 7123.43 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9953/9953 [00:01<00:00, 7133.09 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
    "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "# Load the tokenizer, model, and data collator\n",
    "MODEL_NAME = \"google/flan-t5-large\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "CONTEXT_LENGTH = 256\n",
    "\n",
    "# We prefix our tasks with \"answer the question\"\n",
    "prefix = \"\"\n",
    "\n",
    "# Define the preprocessing function\n",
    "\n",
    "def preprocess_function(examples):\n",
    "   \"\"\"Add prefix to the sentences, tokenize the text, and set the labels\"\"\"\n",
    "   # The \"inputs\" are the tokenized answer:\n",
    "   inputs = [prefix + doc for doc in examples[\"question\"]]\n",
    "   model_inputs = tokenizer(inputs, max_length=CONTEXT_LENGTH, truncation=True)\n",
    "  \n",
    "   # The \"labels\" are the tokenized outputs:\n",
    "   labels = tokenizer(text_target=examples[\"answer\"], \n",
    "                      max_length=CONTEXT_LENGTH,         \n",
    "                      truncation=True)\n",
    "\n",
    "   model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "   return model_inputs\n",
    "\n",
    "tokenized_dataset = train_ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ca62d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Problem:\\n Simplify the following expression $\\\\left(2 \\\\left(\\\\cos \\\\left(\\\\frac{13 \\\\pi }{90}\\\\right)-i \\\\sin \\\\left(\\\\frac{13 \\\\pi }{90}\\\\right)\\\\right)\\\\right)^9$\\n ',\n",
       " 'answer': 'Answer:\\n $512 \\\\left(-\\\\sqrt{\\\\frac{5}{8}-\\\\frac{\\\\sqrt{5}}{8}}+\\\\frac{1}{4} i \\\\left(1+\\\\sqrt{5}\\\\right)\\\\right)$',\n",
       " 'input_ids': [5289,\n",
       "  10,\n",
       "  180,\n",
       "  10296,\n",
       "  4921,\n",
       "  8,\n",
       "  826,\n",
       "  3893,\n",
       "  1514,\n",
       "  2,\n",
       "  17068,\n",
       "  599,\n",
       "  357,\n",
       "  3,\n",
       "  2,\n",
       "  17068,\n",
       "  599,\n",
       "  2,\n",
       "  509,\n",
       "  7,\n",
       "  3,\n",
       "  2,\n",
       "  17068,\n",
       "  599,\n",
       "  2,\n",
       "  9880,\n",
       "  2,\n",
       "  2368,\n",
       "  3,\n",
       "  2,\n",
       "  102,\n",
       "  23,\n",
       "  3,\n",
       "  2,\n",
       "  2394,\n",
       "  2,\n",
       "  3535,\n",
       "  61,\n",
       "  18,\n",
       "  23,\n",
       "  3,\n",
       "  2,\n",
       "  7,\n",
       "  77,\n",
       "  3,\n",
       "  2,\n",
       "  17068,\n",
       "  599,\n",
       "  2,\n",
       "  9880,\n",
       "  2,\n",
       "  2368,\n",
       "  3,\n",
       "  2,\n",
       "  102,\n",
       "  23,\n",
       "  3,\n",
       "  2,\n",
       "  2394,\n",
       "  2,\n",
       "  3535,\n",
       "  61,\n",
       "  2,\n",
       "  3535,\n",
       "  61,\n",
       "  2,\n",
       "  3535,\n",
       "  61,\n",
       "  2,\n",
       "  1298,\n",
       "  3229,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [11801,\n",
       "  10,\n",
       "  6422,\n",
       "  2122,\n",
       "  3,\n",
       "  2,\n",
       "  17068,\n",
       "  599,\n",
       "  18,\n",
       "  2,\n",
       "  7,\n",
       "  1824,\n",
       "  52,\n",
       "  17,\n",
       "  2,\n",
       "  9880,\n",
       "  2,\n",
       "  755,\n",
       "  2,\n",
       "  927,\n",
       "  2,\n",
       "  18,\n",
       "  2,\n",
       "  9880,\n",
       "  2,\n",
       "  7,\n",
       "  1824,\n",
       "  52,\n",
       "  17,\n",
       "  2,\n",
       "  755,\n",
       "  2,\n",
       "  927,\n",
       "  2,\n",
       "  1220,\n",
       "  2,\n",
       "  9880,\n",
       "  2,\n",
       "  536,\n",
       "  2,\n",
       "  591,\n",
       "  2,\n",
       "  3,\n",
       "  23,\n",
       "  3,\n",
       "  2,\n",
       "  17068,\n",
       "  599,\n",
       "  536,\n",
       "  1220,\n",
       "  2,\n",
       "  7,\n",
       "  1824,\n",
       "  52,\n",
       "  17,\n",
       "  2,\n",
       "  755,\n",
       "  2,\n",
       "  3535,\n",
       "  61,\n",
       "  2,\n",
       "  3535,\n",
       "  61,\n",
       "  3229,\n",
       "  1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['test'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a35f29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1000\n",
      "Problem: Find the norm and argument (phase angle in radians) of $-e <unk> left(<unk> sin <unk> left(<unk> frac<unk> 7 <unk> pi <unk> 180<unk> right)+i <unk> cos <unk> left(<unk> frac<unk> 7 <unk> pi <unk> 180<unk> right)<unk> right)$.</s>\n",
      "Answer: Norm: $e <unk> sqrt<unk> sin <unk> 2<unk> left(<unk> frac<unk> 7 <unk> pi <unk> 180<unk> right)+<unk> cos <unk> 2<unk> left(<unk> frac<unk> 7 <unk> pi <unk> 180<unk> right)<unk> $ Argument: $-<unk> frac<unk> 97 <unk> pi <unk> 180<unk> $</s>\n",
      "Case 1001\n",
      "Problem: Find all real solutions to $| 7-19 x| =2$</s>\n",
      "Answer: $<unk> left<unk> left<unk> x<unk> to <unk> frac<unk> 5<unk> 19<unk> right<unk>,<unk> left<unk> x<unk> to <unk> frac<unk> 9<unk> 19<unk> right<unk> right<unk> $</s>\n",
      "Case 1002\n",
      "Problem: Factor the following quadratic: $10 x<unk> 2+220 x+1170$</s>\n",
      "Answer: $10 (-x-13) (-x-9)$</s>\n",
      "Case 1003\n",
      "Problem: Find the smallest $x$ such that $x <unk> equiv 5 <unk> pmod<unk> 11<unk> $ $x <unk> equiv 20 <unk> pmod<unk> 15<unk> $ $x <unk> equiv 5 <unk> pmod<unk> 9<unk> $</s>\n",
      "Answer: $5$</s>\n",
      "Case 1004\n",
      "Problem: Simplify $(((25-4)+17)+1) <unk> left(<unk> frac<unk> 1<unk> 3<unk> ((8+10)-25)-20<unk> right)$.</s>\n",
      "Answer: $-871$</s>\n",
      "Case 1005\n",
      "Problem: Simplify the following expression $<unk> left(2 <unk> left(<unk> cos <unk> left(<unk> frac<unk> 11 <unk> pi <unk> 90<unk> right)+i <unk> sin <unk> left(<unk> frac<unk> 11 <unk> pi <unk> 90<unk> right)<unk> right)<unk> right)<unk> 6$</s>\n",
      "Answer: $64 <unk> left(-<unk> sin <unk> left(<unk> frac<unk> 7 <unk> pi <unk> 30<unk> right)+i <unk> cos <unk> left(<unk> frac<unk> 7 <unk> pi <unk> 30<unk> right)<unk> right)$</s>\n",
      "Case 1006\n",
      "Problem: Simplify $<unk> frac<unk> ((18+3)-11)-23<unk> 24-8<unk> $.</s>\n",
      "Answer: $-<unk> frac<unk> 13<unk> 16<unk> $</s>\n",
      "Case 1007\n",
      "Problem: Find the sum $p(x) + q(x)$ of the following two polynomials: $p(x) = -x<unk> 2+2 x-12$, $q(x) = -2 <unk> left(5 x<unk> 2-7 x+1<unk> right)$</s>\n",
      "Answer: $-11 x<unk> 2+16 x-14$</s>\n",
      "Case 1008\n",
      "Problem: Multiply and expand $p(x) = -8 <unk> sqrt<unk> 3<unk> x<unk> 2+7 <unk> sqrt<unk> 3<unk> x+5 <unk> sqrt<unk> 3<unk> $ and $q(x) = 3 <unk> sqrt<unk> 3<unk> x<unk> 2-2 <unk> sqrt<unk> 3<unk> x+5 <unk> sqrt<unk> 3<unk> $</s>\n",
      "Answer: $-72 x<unk> 4+111 x<unk> 3-117 x<unk> 2+75 x+75$</s>\n",
      "Case 1009\n",
      "Problem: Find the greatest common disvior of $<unk> left<unk> frac<unk> 4648<unk> 9<unk>,630<unk> right<unk> $.</s>\n",
      "Answer: $<unk> frac<unk> 14<unk> 9<unk> $</s>\n"
     ]
    }
   ],
   "source": [
    "train_ds = tokenized_dataset['train']\n",
    "\n",
    "for i in range(1000, min(len(train_ds), 1010)):\n",
    "    question = train_ds[i]['question'] \n",
    "    if len(question) > 3:\n",
    "        print(\"Case\", i)\n",
    "        print(tokenizer.decode(train_ds[i]['input_ids']))\n",
    "        print(tokenizer.decode(train_ds[i]['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6af69a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22446' max='1980552' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  22446/1980552 2:35:16 < 225:46:29, 2.41 it/s, Epoch 0.09/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.043127</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>0.039763</td>\n",
       "      <td>0.039811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "#nltk.download(\"punkt\", quiet=True)\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "   preds, labels = eval_preds\n",
    "   # decode preds and labels\n",
    "   labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "   decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "   decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "   # rougeLSum expects newline after each sentence\n",
    "   decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "   decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "   result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "   return result\n",
    "\n",
    "# Global Parameters\n",
    "L_RATE = 3e-4\n",
    "BATCH_SIZE = 8\n",
    "WEIGHT_DECAY = 0.01\n",
    "SAVE_TOTAL_LIM = 2\n",
    "NUM_EPOCHS = 8\n",
    "SAVE_STEPS=20000\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "   output_dir=\"datasets/integrate_flant5_20240101\",\n",
    "   evaluation_strategy=\"steps\",\n",
    "   learning_rate=L_RATE,\n",
    "   per_device_train_batch_size=BATCH_SIZE,\n",
    "   per_device_eval_batch_size=BATCH_SIZE,\n",
    "   save_steps=SAVE_STEPS,\n",
    "   eval_steps=SAVE_STEPS,\n",
    "   logging_steps=SAVE_STEPS,\n",
    "   weight_decay=WEIGHT_DECAY,\n",
    "   save_total_limit=SAVE_TOTAL_LIM,\n",
    "   num_train_epochs=NUM_EPOCHS,\n",
    "   predict_with_generate=True,\n",
    "   push_to_hub=False,\n",
    "   fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_dataset[\"train\"],\n",
    "   eval_dataset=tokenized_dataset[\"test\"],\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "#cp_path = \"datasets/integrate_flant5_20240101/checkpoint-36000\"\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4e01fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"datasets/amps_mathematica_algebra_numtheory_gptneo_350m/gptneo-350m-985000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86e06cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"datasets/integrate_gptneo_202401/gptneo-350m-5500-loss0.350.model\").to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:symbolic]",
   "language": "python",
   "name": "conda-env-symbolic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
