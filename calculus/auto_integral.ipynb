{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f9fa8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Model successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load symbolicregression model\n",
    "\n",
    "import torch\n",
    "import os, sys\n",
    "import symbolicregression\n",
    "import sympytorch\n",
    "import requests\n",
    "from sympy.core.rules import Transform\n",
    "\n",
    "model_path = \"ckpt/model.pt\" \n",
    "try:\n",
    "    if not os.path.isfile(model_path): \n",
    "        print(\"Downloading model...\")\n",
    "        url = \"https://dl.fbaipublicfiles.com/symbolicregression/model1.pt\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(model_path, 'wb').write(r.content)\n",
    "    if not torch.cuda.is_available():\n",
    "        sr_model = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        sr_model = torch.load(model_path)\n",
    "        sr_model = sr_model.cuda()\n",
    "    print(sr_model.device)\n",
    "    print(\"Model successfully loaded!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"ERROR: model not loaded! path was: {}\".format(model_path))\n",
    "    print(e)    \n",
    "    \n",
    "est = symbolicregression.model.SymbolicTransformerRegressor(\n",
    "                        model=sr_model,\n",
    "                        max_input_points=10001,\n",
    "                        n_trees_to_refine=5,\n",
    "                        rescale=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "254dcf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# CONTEXT_LENGTH = 256\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"xhyi/PT_GPTNEO350_ATG\") \n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"datasets/normalize_symbolic_regression_results_20231215/gptneo-350m-5500.model\")\n",
    "\n",
    "\n",
    "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
    "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "# Load the tokenizer, model, and data collator\n",
    "MODEL_NAME = \"google/flan-t5-base\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"datasets/normalize_symbolic_regression_results_flant5_20231219/flant5-base-36000-loss0.097.model\")\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f68416c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running integration on\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2 t^{2} - 2 t + 2.5$"
      ],
      "text/plain": [
       "2*t**2 - 2*t + 2.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.666666666666667 t^{3} - 1.0 t^{2} + 2.5 t$"
      ],
      "text/plain": [
       "0.666666666666667*t**3 - 1.0*t**2 + 2.5*t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.666666666666667*t**3 - 1.0*t**2 + 2.5*t,\n",
       " array([-4.   , -3.998, -3.996, ...,  3.994,  3.996,  3.998]),\n",
       " array([-68.66666667, -68.58170266, -68.49681062, ...,  36.50791852,\n",
       "         36.56077862,  36.61369466]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "from sympy import sympify, lambdify, symbols, integrate, Interval, Symbol, I, S, oo, plot\n",
    "from IPython.display import display\n",
    "\n",
    "# Given an expr f (of variable t), returns its integral, together with t's and y's for regression\n",
    "def integrate_expr(f, min_x=-4.0, max_x=4.0, increment=0.002, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"Running integration on\")\n",
    "        display(f)\n",
    "    # Compute integration\n",
    "    x, t = symbols(['x','t'])\n",
    "    fi = integrate(f, t)\n",
    "    if verbose:\n",
    "        display(fi)\n",
    "        #plot(fi, (t, min_x, max_x))\n",
    "    # Generate data for symbolic regression\n",
    "    fl = lambdify((t), fi, \"numpy\")\n",
    "    ts = np.arange(min_x, max_x, increment)\n",
    "    ys = fl(ts)\n",
    "    return fi, ts, ys\n",
    "    \n",
    "integrate_expr(sympify(\"2*t**2-t*2+2.5\"), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bb80a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.67 t^{3} - 1.0 t^{2} + 2.5 t$"
      ],
      "text/plain": [
       "0.67*t**3 - 1.0*t**2 + 2.5*t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.67 t^{3} - t^{2} + 2.5 t$"
      ],
      "text/plain": [
       "0.67*t**3 - t**2 + 2.5*t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff1:\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0$"
      ],
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff2:\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - 7.812500000004 \\cdot 10^{-5} t^{3}$"
      ],
      "text/plain": [
       "-7.812500000004e-5*t**3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.utils import *\n",
    "\n",
    "def round_expr(expr, num_digits=2):\n",
    "    return expr.xreplace(Transform(lambda x: x.round(num_digits), lambda x: isinstance(x, sp.Float)))\n",
    "\n",
    "# Run symbolic regression on given data\n",
    "# Returns: (raw regressed expr, rounded expr, model refined expr)\n",
    "@timeout(15)\n",
    "def symbolic_regress(sr_model, xs, ys, generate_refinement=True, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"Running Symbolic Regression...\")\n",
    "    ##Example of data\n",
    "    xs = np.reshape(xs, (len(xs),1))\n",
    "    ys = np.reshape(ys, (len(ys),1))\n",
    "    sr_model.fit(xs,ys)\n",
    "    #\n",
    "    replace_ops = {\"add\": \"+\", \"mul\": \"*\", \"sub\": \"-\", \"pow\": \"**\", \"inv\": \"1/\"}\n",
    "    model_str = sr_model.retrieve_tree(with_infos=True)[\"relabed_predicted_tree\"].infix()\n",
    "    for op,replace_op in replace_ops.items():\n",
    "        model_str = model_str.replace(op,replace_op)\n",
    "    #\n",
    "    raw_expr = sp.parse_expr(model_str)\n",
    "    x_0, t = symbols(['x_0', 't'])\n",
    "    raw_expr = raw_expr.subs(x_0, t)\n",
    "    if verbose:\n",
    "        display(raw_expr)\n",
    "    #\n",
    "    expr = sp.expand(raw_expr)\n",
    "    rounded_expr = round_expr(expr)\n",
    "    if verbose:\n",
    "        display(rounded_expr)\n",
    "    #\n",
    "    # Encode some input text\n",
    "    if generate_refinement:\n",
    "        prompt = str(rounded_expr)\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "        #\n",
    "        # Generate text\n",
    "        output = model.generate(input_ids, max_length=50, num_return_sequences=1, temperature=0.1)\n",
    "        #\n",
    "        # Decode and print the output\n",
    "        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        generated_expr = sympify(generated_text)\n",
    "        if verbose:\n",
    "            display(generated_expr)\n",
    "        #\n",
    "    else:\n",
    "        generated_expr = None\n",
    "    return raw_expr, rounded_expr, generated_expr\n",
    "\n",
    "\n",
    "fi, ts, ys = integrate_expr(sympify(\"2*t**2-t*2+2.5\"), verbose=False)\n",
    "rounded_fi = round_expr(fi)\n",
    "display(rounded_fi)\n",
    "raw_expr, rounded_expr, generated_expr = symbolic_regress(est, ts, ys, verbose=False)\n",
    "display(generated_expr)\n",
    "\n",
    "print(\"Diff1:\")\n",
    "display(rounded_fi-rounded_expr)\n",
    "print(\"Diff2:\")\n",
    "display(rounded_fi-generated_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3049e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def load_expressions(filepaths):\n",
    "    lines = []\n",
    "    for filepath in filepaths:\n",
    "        fin = open(filepath, 'r')\n",
    "        lines.extend(fin.readlines())\n",
    "        fin.close()\n",
    "    #\n",
    "    random.shuffle(lines)\n",
    "    exprs = set()\n",
    "    for line in lines:\n",
    "        data = json.loads(line)\n",
    "        for k,v in data.items():\n",
    "            if k in ('f_t', 'g_t'):\n",
    "                try:\n",
    "                    if 'sqrt' not in v[1]:\n",
    "                        expr = sympify(v[1])\n",
    "                        exprs.add(expr)\n",
    "                except:\n",
    "                    continue\n",
    "    return exprs\n",
    "\n",
    "#exprs = load_expressions(['datasets/parametric_equations.json'])  #'datasets/function_evaluation.json', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41e43ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run symbolic regression on each case\n",
    "\n",
    "# seen_exprs = set()\n",
    "# fin = open(\"datasets/parametric_equations_integral_results.json\", \"r\")\n",
    "# lines = fin.readlines()\n",
    "# for line in lines:\n",
    "#     result = json.loads(line)\n",
    "#     expr = result[\"original\"]\n",
    "#     seen_exprs.add(expr)\n",
    "# fin.close()\n",
    "# print(f\"{len(seen_exprs)} exprs loaded\")\n",
    "\n",
    "# fout = open(\"datasets/parametric_equations_integral_results.json\", \"a\")\n",
    "# num_seen = 0\n",
    "# num_seen_changed = False\n",
    "\n",
    "# for f in exprs:\n",
    "#     if str(f) in seen_exprs:\n",
    "#         num_seen+=1\n",
    "#         num_seen_changed = True\n",
    "#         continue\n",
    "#     else:\n",
    "#         num_seen_changed = False\n",
    "#     if num_seen_changed:\n",
    "#         print(f\"{num_seen} exprs ignored\")\n",
    "#     #print(\"Original expr and its integral:\")\n",
    "#     #display(f)\n",
    "#     #print(f)\n",
    "#     try:\n",
    "#         fi, xs, ys = integrate_expr(f, verbose=False)\n",
    "#         x, t = symbols(['x','t'])\n",
    "#         fi = fi.subs({x:t})\n",
    "#         rounded_fi = round_expr(fi)\n",
    "#         #display(rounded_fi)\n",
    "#         raw_expr, rounded_expr, generated_expr = symbolic_regress(est, xs, ys, generate_refinement=True, verbose=False)\n",
    "# #         print(\"Generated expr:\")\n",
    "# #         display(generated_expr)\n",
    "#         results = {\"original\":str(f),\n",
    "#                    \"integral\":str(fi),\n",
    "#                    \"rounded_integral\":str(rounded_fi),\n",
    "#                    \"regressed\":str(raw_expr),\n",
    "#                    \"rounded_regressed\":str(rounded_expr),\n",
    "#                    \"generated_regressed\":str(generated_expr),\n",
    "#                    \"diff_rounded\": str(rounded_fi-rounded_expr),\n",
    "#                    \"diff_generated\": str(rounded_fi-generated_expr)\n",
    "#                   }\n",
    "#         fout.write(json.dumps(results))\n",
    "#         fout.write('\\n')\n",
    "#         fout.flush()\n",
    "#     except:\n",
    "#         print(\"Failed to run symbolic regression\")\n",
    "#         continue\n",
    "#     #     print(\"Diff1:\")\n",
    "#     #     display(rounded_fi-rounded_expr)\n",
    "#     #     print(\"Diff2:\")\n",
    "#     #     display(rounded_fi-generated_expr)\n",
    "\n",
    "# fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a229cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the accuracy of symbolic regression\n",
    "\n",
    "# from sympy import evalf, N\n",
    "# from utils.utils import *\n",
    "\n",
    "\n",
    "# # Check if f1 and f2 are almost equal.\n",
    "# # Note: Relative error is defined based on f1. Please use the original expression as f1.\n",
    "# def almost_equal(f1, f2, max_abs_error=0.011, max_relative_error=0.011, verbose=False):\n",
    "#     expr = f1-f2\n",
    "#     coeff_pairs = None\n",
    "#     try:\n",
    "#         coeff_pairs = get_coefficients_and_exponents(expr)\n",
    "#     except:\n",
    "#         print(\"Cannot get_coefficients_and_exponents\")\n",
    "#         print(str(expr))\n",
    "#     if coeff_pairs is None:\n",
    "#         constants = get_all_constants(expr)\n",
    "#     else:\n",
    "#         constants = [p[0] for p in coeff_pairs]\n",
    "#     # Check if all diffs are within max_abs_error\n",
    "#     violators = [c for c in constants if c == sp.nan or abs(c) > max_abs_error]\n",
    "#     if verbose:\n",
    "#         print(\"Violating constants:\", violators)\n",
    "#     if len(violators) == 0:\n",
    "#         return True\n",
    "#     # Check if all violating diffs are within max_relative_error\n",
    "#     try:\n",
    "#         coeffs1 = get_polynomial_coeffs(f1)\n",
    "#         coeffs2 = get_polynomial_coeffs(f2)\n",
    "#     except:\n",
    "#         return False\n",
    "#     for i in range(len(coeffs1)):\n",
    "#         if abs(coeffs1[i] - coeffs2[i]) > max_abs_error and \\\n",
    "#            abs(coeffs1[i] - coeffs2[i]) > max_relative_error*abs(coeffs1[i]):\n",
    "#             return False\n",
    "#     return True\n",
    "    \n",
    "\n",
    "# fin = open(\"datasets/parametric_equations_integral_results.json\", \"r\")\n",
    "# lines = fin.readlines()\n",
    "\n",
    "# num_total, qualified_rounded, qualified_generated = 0, 0, 0\n",
    "# for line in lines:\n",
    "#     result = json.loads(line)\n",
    "#     if \"diff_rounded\" not in result or \"diff_generated\" not in result:\n",
    "#         continue\n",
    "#     rounded_integral = N(sympify(result[\"rounded_integral\"]))\n",
    "#     rounded_regressed = N(sympify(result[\"rounded_regressed\"]))\n",
    "#     try:\n",
    "#         rounded_regressed = filter_non_polynomial(rounded_regressed)\n",
    "#     except:\n",
    "#         print(\"Cannot filter non-polynomials on\", str(rounded_regressed))\n",
    "#     #generated_regressed = N(sympify(result[\"generated_regressed\"]))\n",
    "#     diff_rounded = rounded_integral - rounded_regressed\n",
    "#     #diff_generated = sympify(result[\"diff_generated\"])\n",
    "#     num_total += 1\n",
    "#     if almost_equal(rounded_integral, rounded_regressed, verbose=True):\n",
    "#         qualified_rounded += 1\n",
    "#     else:\n",
    "#         display(rounded_integral)\n",
    "#         display(rounded_regressed)\n",
    "#         print(rounded_regressed)\n",
    "#         display(diff_rounded)\n",
    "# #     if is_close_to_zero(diff_generated, True):\n",
    "# #         qualified_generated += 1\n",
    "    \n",
    "# fin.close()\n",
    "\n",
    "# print(num_total, qualified_rounded, qualified_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2be57761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 processed\n",
      "200 processed\n",
      "300 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.82 t^{3} - 0.94 t^{2} - \\frac{1.13 t^{2}}{9.82 \\cos{\\left(0.89 \\sqrt{\\arctan{\\left(0.0 \\right)} + 0.85} + 0.08 \\right)} - 0.07} + 0.39 t + \\frac{0.64 t}{9.82 \\cos{\\left(0.89 \\sqrt{\\arctan{\\left(0.0 \\right)} + 0.85} + 0.08 \\right)} - 0.07}$"
      ],
      "text/plain": [
       "0.82*t**3 - 0.94*t**2 - 1.13*t**2/(9.82*cos(0.89*sqrt(arctan(0.0) + 0.85) + 0.08) - 0.07) + 0.39*t + 0.64*t/(9.82*cos(0.89*sqrt(arctan(0.0) + 0.85) + 0.08) - 0.07)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.03 t^{2} \\arctan{\\left(79.74 \\right)} - 3.71 t^{2} + 0.67 t$"
      ],
      "text/plain": [
       "0.03*t**2*arctan(79.74) - 3.71*t**2 + 0.67*t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 24.49 t^{3} + 128.57 t^{2} + 227.05 t + \\frac{187.99 t}{-90.2 + \\frac{6.2}{- 0.08 \\arctan^{2}{\\left(0.0 \\right)} - 4.46}}$"
      ],
      "text/plain": [
       "24.49*t**3 + 128.57*t**2 + 227.05*t + 187.99*t/(-90.2 + 6.2/(-0.08*arctan(0.0)**2 - 4.46))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 processed\n",
      "700 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 3.75 t^{2} - 1.07 t \\arctan{\\left(0.0 \\right)} - 8.25 t$"
      ],
      "text/plain": [
       "3.75*t**2 - 1.07*t*arctan(0.0) - 8.25*t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 processed\n",
      "900 processed\n",
      "1000 processed\n",
      "1100 processed\n",
      "1200 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - 0.03 t^{2} \\cos{\\left(0.01 \\arctan{\\left(-0.331321606892383 \\right)} + 0.05 \\right)} + 1.78 t^{2} - 0.15 t \\cos{\\left(0.01 \\arctan{\\left(-0.331321606892383 \\right)} + 0.05 \\right)} + 8.15 t$"
      ],
      "text/plain": [
       "-0.03*t**2*cos(0.01*arctan(-0.331321606892383) + 0.05) + 1.78*t**2 - 0.15*t*cos(0.01*arctan(-0.331321606892383) + 0.05) + 8.15*t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 processed\n",
      "1400 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.33 t^{3} - 11.14 t^{2} + 31.05 t + 2.75 \\arctan{\\left(0.04 \\right)} - 0.11$"
      ],
      "text/plain": [
       "1.33*t**3 - 11.14*t**2 + 31.05*t + 2.75*arctan(0.04) - 0.11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 processed\n",
      "1600 processed\n",
      "1700 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 5.33 t^{3} - 27.95 t^{2} - \\frac{0.58 t^{2}}{7.14 \\arctan{\\left(74.77 \\right)} + 0.8} + 48.87 t + \\frac{1.53 t}{7.14 \\arctan{\\left(74.77 \\right)} + 0.8}$"
      ],
      "text/plain": [
       "5.33*t**3 - 27.95*t**2 - 0.58*t**2/(7.14*arctan(74.77) + 0.8) + 48.87*t + 1.53*t/(7.14*arctan(74.77) + 0.8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 processed\n",
      "1900 processed\n",
      "2000 processed\n",
      "2100 processed\n",
      "2200 processed\n",
      "2300 processed\n",
      "2400 processed\n",
      "2500 processed\n",
      "2600 processed\n",
      "2700 processed\n",
      "2800 processed\n",
      "2900 processed\n",
      "3000 processed\n",
      "3100 processed\n",
      "3200 processed\n",
      "3300 processed\n",
      "3400 processed\n",
      "3500 processed\n",
      "3600 processed\n",
      "Cannot filter non-polynomials on -2.5*t**2 + 0.14*t**2/(2.65*t*arctan(27.28*t + 0.04)**2 - 58.47*t*arctan(27.28*t + 0.04) - 531.59*t + 0.04*arctan(27.28*t + 0.04)**2 - 0.79*arctan(27.28*t + 0.04) - 7.19) - 1.5*t + 0.08*t/(2.65*t*arctan(27.28*t + 0.04)**2 - 58.47*t*arctan(27.28*t + 0.04) - 531.59*t + 0.04*arctan(27.28*t + 0.04)**2 - 0.79*arctan(27.28*t + 0.04) - 7.19)\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - 2.5 t^{2} + \\frac{0.14 t^{2}}{2.65 t \\arctan^{2}{\\left(27.28 t + 0.04 \\right)} - 58.47 t \\arctan{\\left(27.28 t + 0.04 \\right)} - 531.59 t + 0.04 \\arctan^{2}{\\left(27.28 t + 0.04 \\right)} - 0.79 \\arctan{\\left(27.28 t + 0.04 \\right)} - 7.19} - 1.5 t + \\frac{0.08 t}{2.65 t \\arctan^{2}{\\left(27.28 t + 0.04 \\right)} - 58.47 t \\arctan{\\left(27.28 t + 0.04 \\right)} - 531.59 t + 0.04 \\arctan^{2}{\\left(27.28 t + 0.04 \\right)} - 0.79 \\arctan{\\left(27.28 t + 0.04 \\right)} - 7.19}$"
      ],
      "text/plain": [
       "-2.5*t**2 + 0.14*t**2/(2.65*t*arctan(27.28*t + 0.04)**2 - 58.47*t*arctan(27.28*t + 0.04) - 531.59*t + 0.04*arctan(27.28*t + 0.04)**2 - 0.79*arctan(27.28*t + 0.04) - 7.19) - 1.5*t + 0.08*t/(2.65*t*arctan(27.28*t + 0.04)**2 - 58.47*t*arctan(27.28*t + 0.04) - 531.59*t + 0.04*arctan(27.28*t + 0.04)**2 - 0.79*arctan(27.28*t + 0.04) - 7.19)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700 processed\n",
      "3800 processed\n",
      "3900 processed\n",
      "4000 processed\n",
      "4100 processed\n",
      "4200 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 3.7 t^{2} + 7.07 t - \\frac{3.2 t}{4.97 - 0.4 \\arctan{\\left(0.58 \\right)}}$"
      ],
      "text/plain": [
       "3.7*t**2 + 7.07*t - 3.2*t/(4.97 - 0.4*arctan(0.58))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.44 t^{2} - 3.67 t \\arctan{\\left(0.02 \\right)} + 33.14 t + 0.01$"
      ],
      "text/plain": [
       "1.44*t**2 - 3.67*t*arctan(0.02) + 33.14*t + 0.01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - 11.59 t \\arctan{\\left(0.05 \\right)} - 8.58 t - 0.03 \\arctan{\\left(0.05 \\right)}$"
      ],
      "text/plain": [
       "-11.59*t*arctan(0.05) - 8.58*t - 0.03*arctan(0.05)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400 processed\n",
      "4500 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.02 t^{2} \\arctan{\\left(0.43 \\right)} - 4.31 t^{2}$"
      ],
      "text/plain": [
       "0.02*t**2*arctan(0.43) - 4.31*t**2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4600 processed\n",
      "4700 processed\n",
      "4800 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - 2.15 t^{2} \\arctan{\\left(-5134.7509765625 \\right)} + 0.22 t^{2} + 0.01 t \\arctan{\\left(-5134.7509765625 \\right)} + 7.62 t$"
      ],
      "text/plain": [
       "-2.15*t**2*arctan(-5134.7509765625) + 0.22*t**2 + 0.01*t*arctan(-5134.7509765625) + 7.62*t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4900 processed\n",
      "5000 processed\n",
      "Cannot filter non-polynomials on 1.6*t**2 + 2.0*t + 1.26*t/(-1.43*t**2 + 1185.29*t*(0.48 - 1/(-0.37*t - 7.04))**0.5*arctan(-0.02*t - 93.9) - 13269.35*t*(0.48 - 1/(-0.37*t - 7.04))**0.5 + 0.17*t*arctan(-0.02*t - 93.9)**2 - 3.8*t*arctan(-0.02*t - 93.9) + 989609.4*t - 2066773.52*t/(-0.37*t - 7.04) + 0.85*(0.48 - 1/(-0.37*t - 7.04))**0.5*arctan(-0.02*t - 93.9) - 9.48*(0.48 - 1/(-0.37*t - 7.04))**0.5 + 707.11 - 1476.79/(-0.37*t - 7.04))\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.6 t^{2} + 2.0 t + \\frac{1.26 t}{- 1.43 t^{2} + 1185.29 t \\left(0.48 - \\frac{1}{- 0.37 t - 7.04}\\right)^{0.5} \\arctan{\\left(- 0.02 t - 93.9 \\right)} - 13269.35 t \\left(0.48 - \\frac{1}{- 0.37 t - 7.04}\\right)^{0.5} + 0.17 t \\arctan^{2}{\\left(- 0.02 t - 93.9 \\right)} - 3.8 t \\arctan{\\left(- 0.02 t - 93.9 \\right)} + 989609.4 t - \\frac{2066773.52 t}{- 0.37 t - 7.04} + 0.85 \\left(0.48 - \\frac{1}{- 0.37 t - 7.04}\\right)^{0.5} \\arctan{\\left(- 0.02 t - 93.9 \\right)} - 9.48 \\left(0.48 - \\frac{1}{- 0.37 t - 7.04}\\right)^{0.5} + 707.11 - \\frac{1476.79}{- 0.37 t - 7.04}}$"
      ],
      "text/plain": [
       "1.6*t**2 + 2.0*t + 1.26*t/(-1.43*t**2 + 1185.29*t*(0.48 - 1/(-0.37*t - 7.04))**0.5*arctan(-0.02*t - 93.9) - 13269.35*t*(0.48 - 1/(-0.37*t - 7.04))**0.5 + 0.17*t*arctan(-0.02*t - 93.9)**2 - 3.8*t*arctan(-0.02*t - 93.9) + 989609.4*t - 2066773.52*t/(-0.37*t - 7.04) + 0.85*(0.48 - 1/(-0.37*t - 7.04))**0.5*arctan(-0.02*t - 93.9) - 9.48*(0.48 - 1/(-0.37*t - 7.04))**0.5 + 707.11 - 1476.79/(-0.37*t - 7.04))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 3.1 t^{2} + 254.35 t \\arctan{\\left(-0.0022066 \\right)} - 2.85 t + 0.03 \\arctan{\\left(-0.0022066 \\right)}$"
      ],
      "text/plain": [
       "3.1*t**2 + 254.35*t*arctan(-0.0022066) - 2.85*t + 0.03*arctan(-0.0022066)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5200 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - 2.0 t^{2} - 1.5 t + \\frac{0.05}{12.26 t + \\tilde{\\infty} t + \\tilde{\\infty}}$"
      ],
      "text/plain": [
       "-2.0*t**2 - 1.5*t + 0.05/(12.26*t + zoo*t + zoo)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5300 processed\n",
      "5400 processed\n",
      "5500 processed\n",
      "Skipping {\"original\": \"(11*t - 12)**2/3\", \"integral\": \"121*t**3/9 - 44*t**2 + 48*t\", \"rounded_integral\": \"121*t**3/9 - 44*t**2 + 48*t\", \"regressed\": \"-2.362714929808825*t + (1.3421100639658838*t - 0.034186530761226524)*(26.407514837270834*(0.6159048132400425*t - 1)**2 + 10.288924736951953) + 1.2545246034571302\", \"rounded_regressed\": \"13.44*t**3 - 44.0*t**2 + 48.0*t\", \"generated_regressed\": \"121*t**3/9 - 44*t**2 + 48*t\", \"diff_rounded\": \"0.004517*t**3\", \"diff_generated\": \"0\"}\n",
      "\n",
      "5600 processed\n",
      "5700 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - 1.5 t^{2} - 0.01 t \\arctan{\\left(62.87 \\right)} + 4.68 t$"
      ],
      "text/plain": [
       "-1.5*t**2 - 0.01*t*arctan(62.87) + 4.68*t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5800 processed\n",
      "Cannot filter non-polynomials on 0.06*t**2*(0.93 + 1/(6415115.33*t**2*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8))**2 + 158.34*t**2*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8)) - 5937.54*t*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8))**2 - 0.15*t*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8)) + 1.37*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8))**2))**0.5 + 1.77*t**2 - 0.07*t*(0.93 + 1/(6415115.33*t**2*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8))**2 + 158.34*t**2*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8)) - 5937.54*t*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8))**2 - 0.15*t*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8)) + 1.37*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8))**2))**0.5 - 1.94*t\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.06 t^{2} \\left(0.93 + \\frac{1}{6415115.33 t^{2} \\left|{- 0.12 t + 2.02 + \\frac{0.05}{10.1 \\cos^{2}{\\left(0.88 t \\right)} + 0.8}}\\right|^{2} + 158.34 t^{2} \\left|{- 0.12 t + 2.02 + \\frac{0.05}{10.1 \\cos^{2}{\\left(0.88 t \\right)} + 0.8}}\\right| - 5937.54 t \\left|{- 0.12 t + 2.02 + \\frac{0.05}{10.1 \\cos^{2}{\\left(0.88 t \\right)} + 0.8}}\\right|^{2} - 0.15 t \\left|{- 0.12 t + 2.02 + \\frac{0.05}{10.1 \\cos^{2}{\\left(0.88 t \\right)} + 0.8}}\\right| + 1.37 \\left|{- 0.12 t + 2.02 + \\frac{0.05}{10.1 \\cos^{2}{\\left(0.88 t \\right)} + 0.8}}\\right|^{2}}\\right)^{0.5} + 1.77 t^{2} - 0.07 t \\left(0.93 + \\frac{1}{6415115.33 t^{2} \\left|{- 0.12 t + 2.02 + \\frac{0.05}{10.1 \\cos^{2}{\\left(0.88 t \\right)} + 0.8}}\\right|^{2} + 158.34 t^{2} \\left|{- 0.12 t + 2.02 + \\frac{0.05}{10.1 \\cos^{2}{\\left(0.88 t \\right)} + 0.8}}\\right| - 5937.54 t \\left|{- 0.12 t + 2.02 + \\frac{0.05}{10.1 \\cos^{2}{\\left(0.88 t \\right)} + 0.8}}\\right|^{2} - 0.15 t \\left|{- 0.12 t + 2.02 + \\frac{0.05}{10.1 \\cos^{2}{\\left(0.88 t \\right)} + 0.8}}\\right| + 1.37 \\left|{- 0.12 t + 2.02 + \\frac{0.05}{10.1 \\cos^{2}{\\left(0.88 t \\right)} + 0.8}}\\right|^{2}}\\right)^{0.5} - 1.94 t$"
      ],
      "text/plain": [
       "0.06*t**2*(0.93 + 1/(6415115.33*t**2*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8))**2 + 158.34*t**2*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8)) - 5937.54*t*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8))**2 - 0.15*t*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8)) + 1.37*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8))**2))**0.5 + 1.77*t**2 - 0.07*t*(0.93 + 1/(6415115.33*t**2*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8))**2 + 158.34*t**2*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8)) - 5937.54*t*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8))**2 - 0.15*t*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8)) + 1.37*Abs(-0.12*t + 2.02 + 0.05/(10.1*cos(0.88*t)**2 + 0.8))**2))**0.5 - 1.94*t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5900 processed\n",
      "6000 processed\n",
      "6100 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 3.6 t^{2} + 0.02 t \\arctan{\\left(0.01 \\right)} - 1.8 t$"
      ],
      "text/plain": [
       "3.6*t**2 + 0.02*t*arctan(0.01) - 1.8*t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6200 processed\n",
      "6300 processed\n",
      "6400 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.17 t^{2} + 8.33 t + 0.55 \\arctan{\\left(0.0 \\right)}$"
      ],
      "text/plain": [
       "2.17*t**2 + 8.33*t + 0.55*arctan(0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500 processed\n",
      "Cannot filter non-polynomials on 0.9*t**2 - 2.72*t**2/(-3275.62*t**2*tan(7.7 + 2215.0/t) + 69692.71*t**2 - 4.29*t*tan(7.7 + 2215.0/t) + 91.36*t - 9.75*tan(7.7 + 2215.0/t) + 207.34) - 1.8*t + 0.18*t/(-3275.62*t**2*tan(7.7 + 2215.0/t) + 69692.71*t**2 - 4.29*t*tan(7.7 + 2215.0/t) + 91.36*t - 9.75*tan(7.7 + 2215.0/t) + 207.34)\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.9 t^{2} - \\frac{2.72 t^{2}}{- 3275.62 t^{2} \\tan{\\left(7.7 + \\frac{2215.0}{t} \\right)} + 69692.71 t^{2} - 4.29 t \\tan{\\left(7.7 + \\frac{2215.0}{t} \\right)} + 91.36 t - 9.75 \\tan{\\left(7.7 + \\frac{2215.0}{t} \\right)} + 207.34} - 1.8 t + \\frac{0.18 t}{- 3275.62 t^{2} \\tan{\\left(7.7 + \\frac{2215.0}{t} \\right)} + 69692.71 t^{2} - 4.29 t \\tan{\\left(7.7 + \\frac{2215.0}{t} \\right)} + 91.36 t - 9.75 \\tan{\\left(7.7 + \\frac{2215.0}{t} \\right)} + 207.34}$"
      ],
      "text/plain": [
       "0.9*t**2 - 2.72*t**2/(-3275.62*t**2*tan(7.7 + 2215.0/t) + 69692.71*t**2 - 4.29*t*tan(7.7 + 2215.0/t) + 91.36*t - 9.75*tan(7.7 + 2215.0/t) + 207.34) - 1.8*t + 0.18*t/(-3275.62*t**2*tan(7.7 + 2215.0/t) + 69692.71*t**2 - 4.29*t*tan(7.7 + 2215.0/t) + 91.36*t - 9.75*tan(7.7 + 2215.0/t) + 207.34)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.5 t^{2} + 0.57 t \\sin{\\left(0.55 \\arctan{\\left(60889.21 \\right)} - 0.02 \\right)} + 0.01 t$"
      ],
      "text/plain": [
       "2.5*t**2 + 0.57*t*sin(0.55*arctan(60889.21) - 0.02) + 0.01*t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6600 processed\n",
      "6700 processed\n",
      "6800 processed\n",
      "6900 processed\n",
      "7000 processed\n",
      "7100 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.55 t^{3} + 1.46 t^{2} \\arctan{\\left(75.4 \\right)} - 21.56 t^{2} + 0.96 t \\arctan^{2}{\\left(75.4 \\right)} - 28.5 t \\arctan{\\left(75.4 \\right)} + 267.05 t$"
      ],
      "text/plain": [
       "0.55*t**3 + 1.46*t**2*arctan(75.4) - 21.56*t**2 + 0.96*t*arctan(75.4)**2 - 28.5*t*arctan(75.4) + 267.05*t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200 processed\n",
      "7300 processed\n",
      "7400 processed\n",
      "7500 processed\n",
      "7600 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 3.62 t^{2} + \\frac{0.4 t^{2}}{16.36 - 0.28 \\arctan{\\left(0.0 \\right)}} + 0.43 t + \\frac{0.05 t}{16.36 - 0.28 \\arctan{\\left(0.0 \\right)}}$"
      ],
      "text/plain": [
       "3.62*t**2 + 0.4*t**2/(16.36 - 0.28*arctan(0.0)) + 0.43*t + 0.05*t/(16.36 - 0.28*arctan(0.0))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7700 processed\n",
      "7800 processed\n",
      "7900 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - 1.62 t^{3} \\arctan{\\left(0.0 \\right)} + 17.27 t^{3} - 0.2674 t^{2} \\arctan{\\left(0.0 \\right)} + 2.878 t^{2} - 0.01739 t \\arctan{\\left(0.0 \\right)} + 0.1621 t - 0.0008639$"
      ],
      "text/plain": [
       "-1.62*t**3*arctan(0.0) + 17.27*t**3 - 0.2674*t**2*arctan(0.0) + 2.878*t**2 - 0.01739*t*arctan(0.0) + 0.1621*t - 0.0008639"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 processed\n",
      "8100 processed\n",
      "8200 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.08 t^{3} + 0.0250292397660819 t^{2} \\arctan{\\left(0.05 \\right)}$"
      ],
      "text/plain": [
       "0.08*t**3 + 0.0250292397660819*t**2*arctan(0.05)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8300 processed\n",
      "8400 processed\n",
      "8500 processed\n",
      "8600 processed\n",
      "Cannot get_coefficients_and_exponents\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.2 t^{2} + 0.22 t \\arctan{\\left(0.16 \\right)} + 7.56 t$"
      ],
      "text/plain": [
       "1.2*t**2 + 0.22*t*arctan(0.16) + 7.56*t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8700 processed\n",
      "8800 processed\n",
      "8900 processed\n",
      "9000 processed\n"
     ]
    }
   ],
   "source": [
    "# Generate data for regression to infer the rules for integral\n",
    "\n",
    "from sympy import evalf, N\n",
    "from utils.utils import *\n",
    "\n",
    "fin = open(\"datasets/parametric_equations_integral_results.json\", \"r\")\n",
    "lines = fin.readlines()\n",
    "\n",
    "MAX_POWER = 6\n",
    "\n",
    "data_series = [([],[])] * (MAX_POWER+1)\n",
    "data_series = []\n",
    "originals = []\n",
    "integrals = []\n",
    "\n",
    "for i in range(MAX_POWER+1):\n",
    "    data_series.append((list(),list()))\n",
    "\n",
    "for line in lines:\n",
    "    result = json.loads(line)\n",
    "    if \"rounded_regressed\" not in result:\n",
    "        continue\n",
    "    original = N(sympify(result[\"original\"]))\n",
    "    integral = N(sympify(result[\"rounded_regressed\"]))\n",
    "    try:\n",
    "        original = filter_non_polynomial(original)\n",
    "        integral = filter_non_polynomial(integral)\n",
    "    except:\n",
    "        print(\"Cannot filter non-polynomials on\", str(integral))\n",
    "    try:\n",
    "        coeffs_original = get_polynomial_coeffs(original)\n",
    "        coeffs_integral = get_polynomial_coeffs(integral)\n",
    "    except:\n",
    "        print(\"Cannot get_coefficients_and_exponents\")\n",
    "        display(integral)\n",
    "        continue\n",
    "    if original.is_constant():\n",
    "        print(\"Skipping\", line)\n",
    "        continue\n",
    "    xs = list()\n",
    "    for i in range(MAX_POWER+1):\n",
    "        xs.append(i)\n",
    "        xs.append(coeffs_original[i])\n",
    "    for i in range(MAX_POWER+1):\n",
    "        data_series[i][0].append(xs.copy())\n",
    "        data_series[i][1].append(coeffs_integral[i])\n",
    "    if len(data_series[0][1]) % 100 == 0:\n",
    "        print(len(data_series[0][1]), \"processed\")\n",
    "#     if len(data_series[0][1]) == 3844:\n",
    "#         display(original)\n",
    "#         print(original.is_constant())\n",
    "#         display(sympify(result[\"original\"]))\n",
    "#         display(integral)\n",
    "    originals.append(original)\n",
    "    integrals.append(integral)\n",
    "    \n",
    "fin.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "573facaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((4.491977455886875 + (0.04277414834490412 * (-0.4268642389131769 + (0.01981438991014428 * x_0)))) - (1.0990225441131243 + (-0.9454860922513988 * ((31.69247952223734 + (73.39847807253604 * (-0.4268642389131769 + (0.01981438991014428 * x_0)))))**2)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.999818880640652 x_{0}^{2} + 0.994452388751196 x_{0} + 3.4981136576698576$"
      ],
      "text/plain": [
       "1.999818880640652*x_0**2 + 0.994452388751196*x_0 + 3.4981136576698576"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_simple = symbolicregression.model.SymbolicTransformerRegressor(\n",
    "                        model=sr_model,\n",
    "                        max_input_points=10001,\n",
    "                        n_trees_to_refine=5,\n",
    "                        rescale=True\n",
    "                        )\n",
    "\n",
    "\n",
    "x1s = np.reshape(np.asarray(data_series[1][0])[:,1], (len(data_series[1][1]),1))\n",
    "xs = np.asarray(data_series[1][0])\n",
    "ys = np.reshape(data_series[1][1], (len(data_series[1][1]),1))\n",
    "ys = ys + 2*x1s*x1s + 3.5\n",
    "\n",
    "# print(xs[0:10, 1])\n",
    "# print(ys[0:10])\n",
    "\n",
    "est_simple.fit(x1s,ys)\n",
    "\n",
    "replace_ops = {\"add\": \"+\", \"mul\": \"*\", \"sub\": \"-\", \"pow\": \"**\", \"inv\": \"1/\"}\n",
    "model_str = est_simple.retrieve_tree(with_infos=True)[\"relabed_predicted_tree\"].infix()\n",
    "for op,replace_op in replace_ops.items():\n",
    "    model_str = model_str.replace(op,replace_op)\n",
    "    \n",
    "print(model_str)\n",
    "\n",
    "raw_expr = sp.parse_expr(model_str)\n",
    "sp.simplify(sp.expand(raw_expr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2a7b228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/torch/_functorch/deprecated.py:62: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((-12.485996101796932 * 1/((59.428897125824335 + (0.4400843372809274 * (0.0010929793650849954 + (0.02030257522230901 * x_0)))))) - (733.5144801519266 + (-109.17606121067313 * (((0.32142396984495697 + (-6.709960133036752 * (0.0010929793650849954 + (0.02030257522230901 * x_0)))) + ((0.14249416222887892 + (1.8528134966362885e-08 * 1/((0.11767499432962569 + (0.0010929793650849954 + (0.02030257522230901 * x_0)))))) * (-2.915071371303532 + (0.24190824888269735 * (0.0010929793650849954 + (0.02030257522230901 * x_0)))))))**2))) + (-734.9131517254541 + (1482.716911587979 * sin((1.4452354128706124 + (0.13369423518579324 * (0.0010929793650849954 + (0.02030257522230901 * x_0))))))))\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{1.0630107575163575 \\cdot 10^{-5} x_{0}^{6} + 0.0709077116370039 x_{0}^{5} + 0.0078595914625261832 x_{0}^{4} \\sin{\\left(0.0027143372666486393 x_{0} + 1.4453815379109013 \\right)} + 1.3400942828296085 x_{0}^{4} + 52.415349971070804 x_{0}^{3} \\sin{\\left(0.0027143372666486393 x_{0} + 1.4453815379109013 \\right)} - 42.761349494816911 x_{0}^{3} + 918.25940179460633 x_{0}^{2} \\sin{\\left(0.0027143372666486393 x_{0} + 1.4453815379109013 \\right)} - 883.84289377210346 x_{0}^{2} + 5368.5760714351907 x_{0} \\sin{\\left(0.0027143372666486393 x_{0} + 1.4453815379109013 \\right)} - 5292.3961039574214 x_{0} + 10465.470886683563 \\sin{\\left(0.0027143372666486393 x_{0} + 1.4453815379109013 \\right)} - 10358.195351216068}{5.3008038156849632 \\cdot 10^{-6} x_{0}^{4} + 0.035350881588673826 x_{0}^{3} + 0.61930864524311468 x_{0}^{2} + 3.6207694331114662 x_{0} + 7.0583068183090459}$"
      ],
      "text/plain": [
       "(1.0630107575163575e-5*x_0**6 + 0.0709077116370039*x_0**5 + 0.0078595914625261832*x_0**4*sin(0.0027143372666486393*x_0 + 1.4453815379109013) + 1.3400942828296085*x_0**4 + 52.415349971070804*x_0**3*sin(0.0027143372666486393*x_0 + 1.4453815379109013) - 42.761349494816911*x_0**3 + 918.25940179460633*x_0**2*sin(0.0027143372666486393*x_0 + 1.4453815379109013) - 883.84289377210346*x_0**2 + 5368.5760714351907*x_0*sin(0.0027143372666486393*x_0 + 1.4453815379109013) - 5292.3961039574214*x_0 + 10465.470886683563*sin(0.0027143372666486393*x_0 + 1.4453815379109013) - 10358.195351216068)/(5.3008038156849632e-6*x_0**4 + 0.035350881588673826*x_0**3 + 0.61930864524311468*x_0**2 + 3.6207694331114662*x_0 + 7.0583068183090459)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_idx=2\n",
    "\n",
    "x3s = np.reshape(np.asarray(data_series[y_idx][0])[:,3], (len(data_series[y_idx][1]),1))\n",
    "xs = np.asarray(data_series[y_idx][0])\n",
    "ys = np.reshape(data_series[y_idx][1], (len(data_series[y_idx][1]),1))\n",
    "ys = ys + 2*x3s*x3s + 3*x3s + 3.5\n",
    "\n",
    "# print(xs[0:10, 1])\n",
    "# print(ys[0:10])\n",
    "\n",
    "est_simple.fit(x3s,ys)\n",
    "\n",
    "replace_ops = {\"add\": \"+\", \"mul\": \"*\", \"sub\": \"-\", \"pow\": \"**\", \"inv\": \"1/\"}\n",
    "model_str = est_simple.retrieve_tree(with_infos=True)[\"relabed_predicted_tree\"].infix()\n",
    "for op,replace_op in replace_ops.items():\n",
    "    model_str = model_str.replace(op,replace_op)\n",
    "    \n",
    "print(model_str)\n",
    "\n",
    "raw_expr = sp.parse_expr(model_str)\n",
    "sp.simplify(sp.expand(raw_expr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a72d89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9048, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(data_series[1][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4706d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 -0.026666666666666394\n",
      "35 -0.11791731913884451\n",
      "48 129.0\n",
      "67 0.053333333333334565\n",
      "110 4.393333333333333\n",
      "174 7.5\n",
      "203 -0.6319555555555549\n",
      "355 -0.02300000000000002\n",
      "413 0.0344444444444445\n",
      "443 -0.03000000000000025\n",
      "528 -0.5966666666666667\n",
      "567 -44.44444444444444\n",
      "698 0.040000000000000036\n",
      "736 52.77333333333333\n",
      "838 -0.04999999999999982\n",
      "879 -0.040000000000000036\n",
      "896 40.0\n",
      "914 0.020000000000003126\n",
      "935 0.07000000000000028\n",
      "964 -0.023333333333333428\n",
      "969 -0.28999999999999915\n",
      "970 -0.5\n",
      "992 -0.033333333333333215\n",
      "1051 -0.020612244897959542\n",
      "1059 -0.10714285714285765\n",
      "1135 0.030000000000000027\n",
      "1153 -0.03000000000000025\n",
      "1197 0.07888888888888879\n",
      "1207 -0.060000000000002274\n",
      "1221 0.25\n",
      "1238 -0.09999999999999964\n",
      "1248 -0.04816326530612258\n",
      "1263 -0.1999999999999993\n",
      "1270 -0.13666666666666671\n",
      "1293 2.2399999999999998\n",
      "1439 -0.040000000000000036\n",
      "1497 -0.13999999999999968\n",
      "1646 0.04999999999999982\n",
      "1668 -1.215\n",
      "1677 -1.0799999999999998\n",
      "1685 60.0\n",
      "1690 0.021020408163265225\n",
      "1889 -0.040000000000000036\n",
      "1893 0.125\n",
      "1912 6.2\n",
      "1927 -0.23000000000000043\n",
      "1951 -0.11999999999999744\n",
      "2033 0.040000000000000036\n",
      "2041 0.03288395276380829\n",
      "2093 0.04999999999999716\n",
      "2136 12.0\n",
      "2189 0.09999999999999964\n",
      "2231 0.040000000000000036\n",
      "2269 95.33333333333333\n",
      "2306 -0.4571428571428573\n",
      "2332 1.25\n",
      "2358 -0.16000000000000014\n",
      "2434 0.51\n",
      "2505 -2.0\n",
      "2518 0.029999999999999805\n",
      "2537 -0.17999999999999972\n",
      "2641 -0.03122448979591841\n",
      "2673 -15.625\n",
      "2697 0.02857142857142847\n",
      "2767 -0.020000000000000018\n",
      "2785 -0.04857142857142893\n",
      "2815 16.25\n",
      "2920 -18.0\n",
      "2938 -0.02666666666666684\n",
      "3006 -0.49322222222222223\n",
      "3023 0.08299999999999841\n",
      "3037 -0.020000000000000018\n",
      "3060 -0.10999999999999943\n",
      "3128 -29.28\n",
      "3186 -0.020000000000000018\n",
      "3224 -0.029999999999999805\n",
      "3318 -0.03000000000000025\n",
      "3324 21.333333333333332\n",
      "3350 0.028888888888888964\n",
      "3399 1.9\n",
      "3418 -32.625\n",
      "3424 3.2857142857142856\n",
      "3435 1.6\n",
      "3535 0.042857142857142705\n",
      "3612 9.0\n",
      "3666 -112.6666666666665\n",
      "3676 0.027142857142857135\n",
      "3683 -19.6875\n",
      "3826 26.817777777777778\n",
      "3921 -5.76\n",
      "3993 0.1836734693877551\n",
      "4041 -3.09\n",
      "4066 -11.465555555555556\n",
      "4109 129.06\n",
      "4141 0.870000000000001\n",
      "4168 0.03204081632653044\n",
      "4191 -0.16000000000000014\n",
      "4376 -140.55\n",
      "4451 0.030000000000000027\n",
      "4460 3.75\n",
      "4490 -0.029999999999999805\n",
      "4517 0.040000000000000036\n",
      "4519 -0.020000000000000018\n",
      "4548 0.7749999999999986\n",
      "4620 -0.033333333333333215\n",
      "4747 0.06300000000000017\n",
      "4800 -0.25\n",
      "4920 -137.99714285714285\n",
      "4961 0.0842857142857143\n",
      "5213 -15.229999999999999\n",
      "5310 -0.03857142857142826\n",
      "5317 0.20428571428571374\n",
      "5320 2.25\n",
      "5469 0.09999999999999787\n",
      "5600 -0.03999999999999959\n",
      "5638 -0.5\n",
      "5666 0.535\n",
      "5737 -0.04999999999999982\n",
      "5747 1.6\n",
      "5766 -0.024897959183673546\n",
      "5943 3.75\n",
      "5965 14.0625\n",
      "5978 -0.030000000000000027\n",
      "6064 -0.22000000000000064\n",
      "6149 0.28000000000000114\n",
      "6186 -0.13428571428571345\n",
      "6237 0.22333333333333272\n",
      "6293 0.1666666666666714\n",
      "6382 -0.21428571428571427\n",
      "6400 1.25\n",
      "6403 -0.03000000000000025\n",
      "6407 1.75\n",
      "6433 -0.6666666666666666\n",
      "6558 -0.08999999999999986\n",
      "6633 0.050000000000000266\n",
      "6698 -0.03571428571428559\n",
      "6724 -23.64666666666667\n",
      "6734 -0.02999999999999936\n",
      "6779 -0.03000000000000025\n",
      "6910 20.325\n",
      "7019 0.09571428571428564\n",
      "7114 -57.142857142857146\n",
      "7214 -0.09142857142857075\n",
      "7312 -0.1999999999999993\n",
      "7396 -36.36\n",
      "7402 0.0600000000000005\n",
      "7512 11.714285714285714\n",
      "7539 -0.1111111111111111\n",
      "7577 -16.246666666666666\n",
      "7579 -1.6600000000000001\n",
      "7603 0.08714285714285808\n",
      "7673 0.0600000000000005\n",
      "7829 -0.07142857142857142\n",
      "7918 0.51\n",
      "7971 3.9183673469387754\n",
      "8099 35.0\n",
      "8107 -1.375\n",
      "8115 3.81\n",
      "8126 -0.1828571428571415\n",
      "8220 0.5\n",
      "8279 -0.040000000000000036\n",
      "8284 -0.8100000000000023\n",
      "8320 1.2\n",
      "8344 0.7750000000000004\n",
      "8421 0.4500000000000002\n",
      "8443 3.1666666666666665\n",
      "8444 2.51\n",
      "8533 -0.029999999999999805\n",
      "8641 -0.6\n",
      "8656 42.1875\n",
      "8691 -4.5\n",
      "8692 -6.2\n",
      "8790 -0.04000000000000625\n",
      "8809 -0.17000000000000015\n",
      "8897 -1.0\n",
      "8924 12.5\n",
      "8928 0.05500000000000016\n",
      "8971 3.51\n"
     ]
    }
   ],
   "source": [
    "ys = data_series[y_idx][1]\n",
    "xs = np.asarray(data_series[y_idx][0])[:,3]\n",
    "\n",
    "diff = (ys-0.5*xs).flatten()\n",
    "for i in range(len(diff)):\n",
    "    if abs(diff[i]) > 0.02:\n",
    "        print(i, diff[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a24a47c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.        , -17.        ,   2.75      , ...,  -2.        ,\n",
       "       -26.66666667,  -3.5       ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(data_series[y_idx][0])[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "986d6868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " -8.5,\n",
       " 1.38,\n",
       " 54.0,\n",
       " -56.0,\n",
       " -8.25,\n",
       " -3.0,\n",
       " -3.0,\n",
       " 0.67,\n",
       " -4.25,\n",
       " 5.35,\n",
       " 3.88,\n",
       " -2.36,\n",
       " -2.0,\n",
       " 120.0,\n",
       " -0.48,\n",
       " -42.0,\n",
       " -10.0,\n",
       " -18.75,\n",
       " -2.14,\n",
       " 1.3,\n",
       " -2.11,\n",
       " -3.33,\n",
       " 2.1,\n",
       " 8.0,\n",
       " 17.89,\n",
       " 1.14,\n",
       " 1.17,\n",
       " 102.86,\n",
       " -28.89,\n",
       " 0.0,\n",
       " -4.29,\n",
       " 2.64,\n",
       " 27.0,\n",
       " 3.2,\n",
       " 4.2154160141944885,\n",
       " 41.56,\n",
       " -4.33,\n",
       " -10.5,\n",
       " -13.75,\n",
       " 4.0,\n",
       " -12.92,\n",
       " 5.2,\n",
       " -0.66,\n",
       " -0.5,\n",
       " 42.67,\n",
       " -4.2,\n",
       " -2.57,\n",
       " 0.0,\n",
       " 3.25,\n",
       " 9.35,\n",
       " -6.0,\n",
       " 4.5,\n",
       " -11.52,\n",
       " -40.0,\n",
       " 4.38,\n",
       " -1.25,\n",
       " 3.43,\n",
       " 27.13,\n",
       " 3.17,\n",
       " -9.63,\n",
       " 0.189,\n",
       " 3.67,\n",
       " -4.17,\n",
       " 0.25,\n",
       " 2.5,\n",
       " -2.43,\n",
       " 8.72,\n",
       " -1.5,\n",
       " 1.83,\n",
       " -1.17,\n",
       " -3.14,\n",
       " 1.5,\n",
       " 1.57,\n",
       " -1.3,\n",
       " 20.63,\n",
       " 81.0,\n",
       " -7.49,\n",
       " 13.5,\n",
       " -2.67,\n",
       " -35.75,\n",
       " -0.14,\n",
       " 2.0,\n",
       " -1.43,\n",
       " -2.43,\n",
       " -1.38,\n",
       " 20.22,\n",
       " -0.5,\n",
       " -1.83,\n",
       " 2.36,\n",
       " -35.14,\n",
       " -0.56,\n",
       " 3.0,\n",
       " -2.75,\n",
       " 3.89,\n",
       " -27.86,\n",
       " 3.57,\n",
       " -4.25,\n",
       " -19.25,\n",
       " 18.0,\n",
       " -1.79,\n",
       " -30.0,\n",
       " -2.0,\n",
       " 2.71,\n",
       " 0.5,\n",
       " -28.11,\n",
       " -2.0,\n",
       " -5.2,\n",
       " -46.75,\n",
       " 4.0,\n",
       " 0.06,\n",
       " -52.5,\n",
       " -3.07,\n",
       " -3.0,\n",
       " -63.0,\n",
       " -4.4,\n",
       " -2.0,\n",
       " 0.5,\n",
       " 0.33,\n",
       " 22.0,\n",
       " 3.29,\n",
       " -3.75,\n",
       " -0.75,\n",
       " 1.3556327819824219,\n",
       " -3.75,\n",
       " 12.67,\n",
       " 4.04,\n",
       " -1.67,\n",
       " 3.68,\n",
       " 3.17,\n",
       " -7.14,\n",
       " 2.64,\n",
       " 7.44,\n",
       " 4.33,\n",
       " -2.67,\n",
       " -0.25,\n",
       " 0.24,\n",
       " -1.57,\n",
       " 2.5,\n",
       " 22.0,\n",
       " 4.0,\n",
       " -36.67,\n",
       " 3.62,\n",
       " 0.71,\n",
       " -0.62,\n",
       " 3.0,\n",
       " 1.88,\n",
       " 16.67,\n",
       " 50.0,\n",
       " 1.0,\n",
       " -3.17,\n",
       " 4.0,\n",
       " 1.78,\n",
       " 1.33,\n",
       " 56.25,\n",
       " -1.33,\n",
       " 20.0,\n",
       " 26.44,\n",
       " -33.75,\n",
       " 11.67,\n",
       " 26.25,\n",
       " -4.0,\n",
       " 15.68,\n",
       " 2.9,\n",
       " -2.38,\n",
       " 47.6,\n",
       " -51.0,\n",
       " -2.17,\n",
       " 0.62,\n",
       " -16.89,\n",
       " 1.5,\n",
       " -3.14,\n",
       " 7.67,\n",
       " -3.33,\n",
       " 0.0,\n",
       " 0.83,\n",
       " -1.9,\n",
       " -0.8,\n",
       " -23.4,\n",
       " 1.67,\n",
       " -2.0,\n",
       " -25.0,\n",
       " -0.75,\n",
       " 23.14,\n",
       " 3.1,\n",
       " 2.36,\n",
       " -2.25,\n",
       " 3.25,\n",
       " 4.0,\n",
       " -3.37,\n",
       " -1.33,\n",
       " 12.0,\n",
       " 0.36,\n",
       " 17.45,\n",
       " -0.64,\n",
       " 2.79,\n",
       " -3.4,\n",
       " 29.33,\n",
       " 16.56,\n",
       " 15.96,\n",
       " 46.88,\n",
       " 25.56,\n",
       " 2.2,\n",
       " -9.0764,\n",
       " -2.9,\n",
       " 0.63,\n",
       " -1.33,\n",
       " 35.89,\n",
       " 4.0,\n",
       " 1.83,\n",
       " 0.33,\n",
       " 2.33,\n",
       " -22.85,\n",
       " -30.0,\n",
       " 4.0,\n",
       " -2.71,\n",
       " -3.4,\n",
       " 4.5,\n",
       " -34.0,\n",
       " 1.84,\n",
       " 0.33,\n",
       " 1.83,\n",
       " -66.0,\n",
       " 3.7,\n",
       " 0.63,\n",
       " 0.6,\n",
       " 8.88,\n",
       " -3.75,\n",
       " -121.33,\n",
       " -0.4,\n",
       " 4.25,\n",
       " 0.86,\n",
       " -3.43,\n",
       " -17.44,\n",
       " 75.0,\n",
       " 3.37,\n",
       " 4.0,\n",
       " 0.57,\n",
       " 3.43,\n",
       " 1.0,\n",
       " -2.21,\n",
       " 1.0,\n",
       " -4.17,\n",
       " -3.4,\n",
       " 8.75,\n",
       " 0.25,\n",
       " 3.84,\n",
       " -4.17,\n",
       " 1.12,\n",
       " 1.4,\n",
       " 2.33,\n",
       " 3.0,\n",
       " -71.5,\n",
       " 40.0,\n",
       " -1.29,\n",
       " 48.89,\n",
       " 49.5,\n",
       " 14.4,\n",
       " -3.75,\n",
       " 0.79,\n",
       " 22.5,\n",
       " -23.22,\n",
       " -1.14,\n",
       " 61.25,\n",
       " 2.0,\n",
       " -1.2,\n",
       " 0.17,\n",
       " -6.96,\n",
       " -33.75,\n",
       " -2.88,\n",
       " -6.67,\n",
       " 5.69,\n",
       " 2.36,\n",
       " -62.0,\n",
       " 2.001494526863098,\n",
       " -1.88,\n",
       " 0.25,\n",
       " -1.67,\n",
       " -24.0,\n",
       " 3.17,\n",
       " -4.25,\n",
       " -4.25,\n",
       " -1.79,\n",
       " 80.0,\n",
       " -50.29,\n",
       " -1.84,\n",
       " 3.5,\n",
       " 0.29,\n",
       " 0.75,\n",
       " 2.67,\n",
       " 1.5,\n",
       " 31.5,\n",
       " 4.21,\n",
       " -2.86,\n",
       " 1.96,\n",
       " 3.43,\n",
       " -2.29,\n",
       " -0.3,\n",
       " 135.0,\n",
       " 4.4,\n",
       " -3.14,\n",
       " -12.37,\n",
       " -0.91798,\n",
       " -1.7,\n",
       " 0.81,\n",
       " -114.0,\n",
       " 2.64,\n",
       " -1.75,\n",
       " 5.0,\n",
       " -6.08,\n",
       " 30.0,\n",
       " 3.5,\n",
       " 2.25,\n",
       " 67.5,\n",
       " 2.75,\n",
       " 3.17,\n",
       " -12.32,\n",
       " -0.12,\n",
       " 41.25,\n",
       " -0.38,\n",
       " -1.83,\n",
       " -90.0,\n",
       " -4.33,\n",
       " 1.1,\n",
       " 4.4,\n",
       " 0.75,\n",
       " 1.0,\n",
       " 10.56,\n",
       " 1.43,\n",
       " 0.7,\n",
       " 4.2,\n",
       " -2.29,\n",
       " 0.17,\n",
       " -3.83,\n",
       " -1.7,\n",
       " -3.36,\n",
       " -0.9,\n",
       " 2.5,\n",
       " -3.75,\n",
       " 2.17,\n",
       " -0.4,\n",
       " -3.56,\n",
       " -0.9,\n",
       " 9.88,\n",
       " -3.67,\n",
       " 13.5,\n",
       " -1.33,\n",
       " -1.31,\n",
       " 7.11,\n",
       " -0.12,\n",
       " 3.36,\n",
       " -0.25,\n",
       " -1.67,\n",
       " -1.88,\n",
       " -3.63,\n",
       " -0.773,\n",
       " 3.12,\n",
       " 13.13,\n",
       " 8.65,\n",
       " -2.33,\n",
       " -3.5,\n",
       " -3.93,\n",
       " -22.86,\n",
       " 9.6,\n",
       " -12.5,\n",
       " -1.5,\n",
       " 60.0,\n",
       " 30.0,\n",
       " -39.06,\n",
       " -3.8,\n",
       " -4.5,\n",
       " -4.4,\n",
       " -13.12,\n",
       " 1.43,\n",
       " -2.8,\n",
       " 0.83,\n",
       " 44.57,\n",
       " 8.88,\n",
       " -0.8,\n",
       " 13.5,\n",
       " -2.79,\n",
       " 0.76,\n",
       " -0.12,\n",
       " 0.21,\n",
       " -3.75,\n",
       " -2.0,\n",
       " 1.92,\n",
       " 10.06,\n",
       " -3.0,\n",
       " 3.75,\n",
       " 1.75,\n",
       " -0.88,\n",
       " 130.0,\n",
       " -2.67,\n",
       " 3.0,\n",
       " 26.25,\n",
       " -4.4,\n",
       " 0.8,\n",
       " 70.0,\n",
       " 0.3,\n",
       " -11.2,\n",
       " -3.5,\n",
       " 10.31,\n",
       " -4.5,\n",
       " -65.0,\n",
       " -12.0,\n",
       " 30.0,\n",
       " 3.5,\n",
       " -2.57,\n",
       " 8.25,\n",
       " -0.71,\n",
       " -4.36,\n",
       " -4.25,\n",
       " -4.41,\n",
       " -3.0,\n",
       " 15.48,\n",
       " -64.29,\n",
       " 0.38,\n",
       " 2.38,\n",
       " -5.06,\n",
       " 3.12,\n",
       " -1.13,\n",
       " 8.94,\n",
       " -7.12,\n",
       " 49.11,\n",
       " -13.2,\n",
       " 18.6,\n",
       " 3.0,\n",
       " 2.06,\n",
       " -2.2,\n",
       " -4.68,\n",
       " -6.33,\n",
       " 3.63,\n",
       " 4.25,\n",
       " 4.21,\n",
       " 3.43,\n",
       " -23.44,\n",
       " -1.79,\n",
       " -3.83,\n",
       " 2.4,\n",
       " 4.07,\n",
       " -3.5,\n",
       " 1.87,\n",
       " -2.43,\n",
       " 3.71,\n",
       " 4.17,\n",
       " -0.19,\n",
       " -1.83,\n",
       " -1.78,\n",
       " -49.11,\n",
       " 23.22,\n",
       " -3.0,\n",
       " -8.34,\n",
       " -60.0,\n",
       " -13.12,\n",
       " 8.25,\n",
       " -3.6,\n",
       " -2.6,\n",
       " 0.83,\n",
       " -3.75,\n",
       " -3.75,\n",
       " -3.33,\n",
       " 18.0,\n",
       " -7.56,\n",
       " 22.8,\n",
       " -2.5,\n",
       " -3.21,\n",
       " -24.0,\n",
       " -3.83,\n",
       " -1.64,\n",
       " -5.84,\n",
       " 1.25,\n",
       " -0.33,\n",
       " -0.17,\n",
       " -3.0,\n",
       " 27.0,\n",
       " -3.7,\n",
       " 1.5,\n",
       " -117.86,\n",
       " -1.25,\n",
       " 3.5,\n",
       " 26.0,\n",
       " -5.39,\n",
       " -0.88,\n",
       " 1.29,\n",
       " 0.2,\n",
       " -0.61,\n",
       " 0.87,\n",
       " 38.33,\n",
       " 20.0,\n",
       " -60.0,\n",
       " -14.0,\n",
       " 18.0,\n",
       " -4.3,\n",
       " 16.88,\n",
       " -3.0,\n",
       " 0.88,\n",
       " -13.33,\n",
       " -4.17,\n",
       " 1.7,\n",
       " -3.1,\n",
       " -60.67,\n",
       " 3.33,\n",
       " 2.36,\n",
       " 9.96,\n",
       " 1.6,\n",
       " 0.94,\n",
       " 2.0,\n",
       " 5.0,\n",
       " 12.67,\n",
       " 34.22,\n",
       " 0.86,\n",
       " 0.38,\n",
       " 33.6,\n",
       " 3.25,\n",
       " -140.0,\n",
       " -14.14,\n",
       " 2.25,\n",
       " -10.67,\n",
       " -16.33,\n",
       " 9.38,\n",
       " 2.86,\n",
       " 16.0,\n",
       " 37.78,\n",
       " 16.25,\n",
       " -0.52,\n",
       " 1.21,\n",
       " 0.17,\n",
       " 1.07,\n",
       " 1.37,\n",
       " 4.0,\n",
       " 22.75,\n",
       " -21.0,\n",
       " 24.01,\n",
       " -2.0,\n",
       " 0.64,\n",
       " 8.003258094384973,\n",
       " -1.63,\n",
       " 2.25,\n",
       " 4.0,\n",
       " -21.0,\n",
       " -2.0,\n",
       " -3.93,\n",
       " 3.17,\n",
       " 55.25,\n",
       " 1.0,\n",
       " 27.62,\n",
       " -1.8,\n",
       " -1.0,\n",
       " 1.8,\n",
       " -24.5,\n",
       " -81.43,\n",
       " -0.5,\n",
       " -20.14,\n",
       " 72.25,\n",
       " -2.33,\n",
       " -2.0,\n",
       " 36.43,\n",
       " 8.16,\n",
       " 0.8,\n",
       " -1.75,\n",
       " -4.38,\n",
       " -20.0,\n",
       " -2.8,\n",
       " 1.92,\n",
       " 4.38,\n",
       " -6.0,\n",
       " 0.0,\n",
       " 0.5,\n",
       " 4.0,\n",
       " -12.57,\n",
       " 2.25,\n",
       " -1.8,\n",
       " 3.87,\n",
       " 29.75,\n",
       " -11.14,\n",
       " 0.08,\n",
       " -2.1,\n",
       " -0.93,\n",
       " 1.47,\n",
       " -0.25,\n",
       " 0.13,\n",
       " -0.25,\n",
       " 1.25,\n",
       " 1.36,\n",
       " 1.71,\n",
       " -11.43,\n",
       " 1.5,\n",
       " -31.88,\n",
       " -0.63,\n",
       " -6.99,\n",
       " -40.71,\n",
       " 3.71,\n",
       " -12.25,\n",
       " 1.67,\n",
       " 31.5,\n",
       " 7.68,\n",
       " -3.6,\n",
       " 0.7,\n",
       " -10.0,\n",
       " -1.93,\n",
       " 0.37,\n",
       " 0.37,\n",
       " -6.67,\n",
       " -85.0,\n",
       " 0.75,\n",
       " 11.0,\n",
       " -2.17,\n",
       " 3.33,\n",
       " 2.6,\n",
       " -39.0,\n",
       " -56.0,\n",
       " 3.67,\n",
       " 1.44,\n",
       " -0.07,\n",
       " 0.6,\n",
       " -0.36,\n",
       " -0.44,\n",
       " 3.12,\n",
       " -5.88,\n",
       " 3.5,\n",
       " -9.75,\n",
       " 1.67,\n",
       " 22.5,\n",
       " -4.0,\n",
       " 4.0,\n",
       " -39.0,\n",
       " 0.4,\n",
       " -16.0,\n",
       " 4.0,\n",
       " -1.48,\n",
       " 5.31,\n",
       " -4.3,\n",
       " 44.44,\n",
       " -2.12,\n",
       " -1.93,\n",
       " -3.5,\n",
       " -3.5,\n",
       " 0.5,\n",
       " -6.35,\n",
       " -1.67,\n",
       " 0.79,\n",
       " -2.62,\n",
       " 3.25,\n",
       " -1.5,\n",
       " -1.64,\n",
       " -23.0,\n",
       " -2.67,\n",
       " -16.89,\n",
       " -1.17,\n",
       " 22.0,\n",
       " -2.9,\n",
       " -66.67,\n",
       " 1.79,\n",
       " 5.5,\n",
       " 78.0,\n",
       " 4.4,\n",
       " 2.57,\n",
       " -6.67,\n",
       " 4.25,\n",
       " -17.47,\n",
       " 1.53,\n",
       " -3.17,\n",
       " -2.21,\n",
       " 3.63,\n",
       " -1.4,\n",
       " -18.86,\n",
       " -4.25,\n",
       " 41.67,\n",
       " 66.0,\n",
       " 54.0,\n",
       " 1.71,\n",
       " -66.0,\n",
       " 3.17,\n",
       " 5.81,\n",
       " 2.37,\n",
       " 1.07,\n",
       " -1.21,\n",
       " 3.29,\n",
       " -59.5,\n",
       " 17.25,\n",
       " 40.33,\n",
       " -1.2,\n",
       " -3.6,\n",
       " -2.8,\n",
       " -23.25,\n",
       " -1.5,\n",
       " 0.86,\n",
       " -1.14,\n",
       " 3.11,\n",
       " 2.0,\n",
       " 3.58,\n",
       " 60.0,\n",
       " 8.89,\n",
       " -37.33,\n",
       " 1.71,\n",
       " -28.0,\n",
       " 7.6,\n",
       " -5.96,\n",
       " -2.9,\n",
       " -5.0,\n",
       " 2.25,\n",
       " -3.63,\n",
       " -17.5,\n",
       " -2.67,\n",
       " -2.88,\n",
       " -18.01,\n",
       " -8.49,\n",
       " 1.4,\n",
       " -30.0,\n",
       " 11.11,\n",
       " 38.5,\n",
       " -27.0,\n",
       " -0.64,\n",
       " -1.0,\n",
       " -17.14,\n",
       " -0.33,\n",
       " 3.6,\n",
       " -1.5,\n",
       " -4.8,\n",
       " 18.33,\n",
       " -1.5,\n",
       " -2.12,\n",
       " 4.5,\n",
       " 0.83,\n",
       " -6.71,\n",
       " 1.7,\n",
       " -0.4,\n",
       " 1.33,\n",
       " -3.0,\n",
       " -2.63,\n",
       " -18.0,\n",
       " 1.25,\n",
       " 2.5,\n",
       " 16.5,\n",
       " -1.4999933415199485,\n",
       " -0.56,\n",
       " 1.14,\n",
       " 0.67,\n",
       " -3.34,\n",
       " 3.12,\n",
       " 29.25,\n",
       " 70.0,\n",
       " -2.0,\n",
       " 12.74,\n",
       " 0.62,\n",
       " -13.33,\n",
       " -10.08,\n",
       " -0.87,\n",
       " 2.57,\n",
       " 6.6,\n",
       " 5.0,\n",
       " 4.21,\n",
       " -0.29,\n",
       " 34.0070108706597,\n",
       " -3.33,\n",
       " 1.68,\n",
       " 19.5,\n",
       " -78.0,\n",
       " -4.36,\n",
       " -0.9,\n",
       " -0.5,\n",
       " 2.21,\n",
       " 2.79,\n",
       " 3.5,\n",
       " -54.0,\n",
       " 2.9,\n",
       " -1.7,\n",
       " -14.99,\n",
       " 3.62,\n",
       " 110.0,\n",
       " 1.36,\n",
       " -48.0,\n",
       " -3.67,\n",
       " -32.0,\n",
       " -1.19,\n",
       " 27.0,\n",
       " -0.12,\n",
       " -0.12,\n",
       " 0.83,\n",
       " 2.25,\n",
       " 2.5,\n",
       " 44.0,\n",
       " 4.67,\n",
       " -1.21,\n",
       " 39.0,\n",
       " -26.0,\n",
       " -9.8,\n",
       " -0.1,\n",
       " 1.7,\n",
       " 3.79,\n",
       " -2.1,\n",
       " 96.43,\n",
       " -1.0,\n",
       " -81.0,\n",
       " -2.5,\n",
       " -4.33,\n",
       " 3.5,\n",
       " 3.3,\n",
       " 1.86,\n",
       " 15.56,\n",
       " 4.9,\n",
       " 3.4,\n",
       " -3.25,\n",
       " 4.29,\n",
       " 2.0,\n",
       " -16.5,\n",
       " 41.25,\n",
       " 1.36,\n",
       " 0.12,\n",
       " -3.13,\n",
       " -26.67,\n",
       " 0.04,\n",
       " -2.25,\n",
       " -1.5,\n",
       " 65.6,\n",
       " 69.71,\n",
       " -34.67,\n",
       " -2.5,\n",
       " -2.21,\n",
       " -0.12,\n",
       " 3.12,\n",
       " -25.0,\n",
       " -51.33,\n",
       " 33.6,\n",
       " 2.67,\n",
       " -27.5,\n",
       " 2.57,\n",
       " -28.0,\n",
       " 27.62,\n",
       " -0.5,\n",
       " -8.0,\n",
       " 2.88,\n",
       " 26.67,\n",
       " -8.86,\n",
       " -2.5,\n",
       " 1.14,\n",
       " -33.75,\n",
       " -6.05,\n",
       " -4.0,\n",
       " -3.8,\n",
       " -4.0,\n",
       " -4.5,\n",
       " -3.0,\n",
       " -3.0,\n",
       " 2.67,\n",
       " -3.6,\n",
       " -126.0,\n",
       " 3.8,\n",
       " -0.13,\n",
       " -3.8,\n",
       " -3.8,\n",
       " -0.25,\n",
       " 8.0,\n",
       " -55.25,\n",
       " 20.12,\n",
       " -2.93,\n",
       " -0.57,\n",
       " 1.5,\n",
       " 9.78,\n",
       " 1.34,\n",
       " 33.0,\n",
       " 3.64,\n",
       " -15.0,\n",
       " -1.5,\n",
       " 17.5,\n",
       " 3.56,\n",
       " -1.93,\n",
       " -24.0,\n",
       " 3.79,\n",
       " 2.0,\n",
       " -3.9,\n",
       " 63.0,\n",
       " 2.8,\n",
       " -0.83,\n",
       " 33.22,\n",
       " -69.33,\n",
       " -40.89,\n",
       " 3.29,\n",
       " 2.84,\n",
       " 130.71,\n",
       " 1.11,\n",
       " -9.78,\n",
       " -17.28,\n",
       " -3.13,\n",
       " -20.8,\n",
       " -9.32,\n",
       " 21.25,\n",
       " 6.67,\n",
       " -3.0,\n",
       " 4.29,\n",
       " -21.67,\n",
       " -4.0,\n",
       " -2.83,\n",
       " -2.6,\n",
       " -4.1,\n",
       " 0.0,\n",
       " -25.71,\n",
       " -26.67,\n",
       " 10.99,\n",
       " -4.25,\n",
       " 94.29,\n",
       " -1.0,\n",
       " 4.25,\n",
       " 3.86,\n",
       " 0.88,\n",
       " -1.7,\n",
       " -0.9,\n",
       " -1.3,\n",
       " 1.67,\n",
       " -3.88,\n",
       " 30.29,\n",
       " 4.67,\n",
       " 44.0,\n",
       " 59.52,\n",
       " -35.0,\n",
       " 112.67,\n",
       " 1.33,\n",
       " -3.87,\n",
       " 1.75,\n",
       " -2.17,\n",
       " 2.86,\n",
       " -1.07,\n",
       " -1.8,\n",
       " 5.33,\n",
       " 1.0,\n",
       " 2.2,\n",
       " 0.5,\n",
       " 2.83,\n",
       " -45.0,\n",
       " 4.1,\n",
       " -4.1,\n",
       " -2.0,\n",
       " -1.5,\n",
       " -2.75,\n",
       " -3.13,\n",
       " 1.75,\n",
       " -2.25,\n",
       " 0.87,\n",
       " 4.5,\n",
       " -1.87,\n",
       " -2.63,\n",
       " 0.7,\n",
       " 0.5,\n",
       " -1.63,\n",
       " -4.37,\n",
       " 0.83,\n",
       " 41.25,\n",
       " -15.01,\n",
       " 53.33,\n",
       " -2.3,\n",
       " -18.0,\n",
       " 0.07,\n",
       " -7.33,\n",
       " 0.17,\n",
       " -2.5,\n",
       " -17.87,\n",
       " -1.5,\n",
       " 2.64,\n",
       " -20.0,\n",
       " 1.93,\n",
       " 1.83,\n",
       " 1.36,\n",
       " 59.4,\n",
       " -2.69,\n",
       " -1.36,\n",
       " 1.0,\n",
       " 3.78,\n",
       " 108.0,\n",
       " 10.21,\n",
       " 2.5,\n",
       " 3.6,\n",
       " -5.33,\n",
       " -8.64,\n",
       " 4.13,\n",
       " -3.8,\n",
       " 43.0,\n",
       " 29.0,\n",
       " -3.17,\n",
       " -57.0,\n",
       " -3.83258064516129,\n",
       " 3.3,\n",
       " -1.38,\n",
       " 1.1,\n",
       " 4.21,\n",
       " -7.67,\n",
       " -0.29,\n",
       " -45.0,\n",
       " -6.67,\n",
       " -36.57,\n",
       " 1.96,\n",
       " -2.0,\n",
       " 1.8,\n",
       " -2.67,\n",
       " 12.94,\n",
       " 1.79,\n",
       " -41.25,\n",
       " -1.08,\n",
       " -3.5,\n",
       " 76.5,\n",
       " ...]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_series[y_idx][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symbolic",
   "language": "python",
   "name": "symbolic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
