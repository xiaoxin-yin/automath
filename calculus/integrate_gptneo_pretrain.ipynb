{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8aab416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in datasets/amps/mathematica/algebra/complex_norm_and_arg\n",
      "Done with datasets/amps/mathematica/algebra/complex_norm_and_arg\n",
      "50000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/spherical_coordinates\n",
      "Done with datasets/amps/mathematica/algebra/spherical_coordinates\n",
      "100000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/complex_raised_to_exponent\n",
      "Done with datasets/amps/mathematica/algebra/complex_raised_to_exponent\n",
      "150000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/sqrt_equations_w_steps\n",
      "Done with datasets/amps/mathematica/algebra/sqrt_equations_w_steps\n",
      "155000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/multiply_polynomials\n",
      "Done with datasets/amps/mathematica/algebra/multiply_polynomials\n",
      "205000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/log_equations\n",
      "Done with datasets/amps/mathematica/algebra/log_equations\n",
      "255000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/factor_polynomials\n",
      "Done with datasets/amps/mathematica/algebra/factor_polynomials\n",
      "310000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/function_range\n",
      "Done with datasets/amps/mathematica/algebra/function_range\n",
      "320000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/parametric_equations\n",
      "Done with datasets/amps/mathematica/algebra/parametric_equations\n",
      "370000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/quadratic_roots_w_steps\n",
      "Done with datasets/amps/mathematica/algebra/quadratic_roots_w_steps\n",
      "375000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/factor_polynomials_w_steps\n",
      "Done with datasets/amps/mathematica/algebra/factor_polynomials_w_steps\n",
      "380000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/polynomial_gcd\n",
      "Done with datasets/amps/mathematica/algebra/polynomial_gcd\n",
      "430000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/quadratic_roots\n",
      "Done with datasets/amps/mathematica/algebra/quadratic_roots\n",
      "480000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/conic_sections\n",
      "Done with datasets/amps/mathematica/algebra/conic_sections\n",
      "530000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/multiply_polynomials_w_steps\n",
      "Done with datasets/amps/mathematica/algebra/multiply_polynomials_w_steps\n",
      "535000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/function_domain\n",
      "Done with datasets/amps/mathematica/algebra/function_domain\n",
      "545000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/system_of_equations_w_steps\n",
      "Done with datasets/amps/mathematica/algebra/system_of_equations_w_steps\n",
      "550000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/pemdas\n",
      "Done with datasets/amps/mathematica/algebra/pemdas\n",
      "600000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/arithmetic_series\n",
      "Done with datasets/amps/mathematica/algebra/arithmetic_series\n",
      "650000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/solve_abs_value_equation\n",
      "Done with datasets/amps/mathematica/algebra/solve_abs_value_equation\n",
      "700000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/polynomial_arithmetic\n",
      "Done with datasets/amps/mathematica/algebra/polynomial_arithmetic\n",
      "750000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/geometric_series\n",
      "Done with datasets/amps/mathematica/algebra/geometric_series\n",
      "800000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/polynomial_division_equation\n",
      "Done with datasets/amps/mathematica/algebra/polynomial_division_equation\n",
      "850000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/sqrt_equations\n",
      "Done with datasets/amps/mathematica/algebra/sqrt_equations\n",
      "900000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/exponential_equations\n",
      "Done with datasets/amps/mathematica/algebra/exponential_equations\n",
      "950000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/find_roots\n",
      "Done with datasets/amps/mathematica/algebra/find_roots\n",
      "960000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/complete_square\n",
      "Done with datasets/amps/mathematica/algebra/complete_square\n",
      "1010000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/complex_arithmetic\n",
      "Done with datasets/amps/mathematica/algebra/complex_arithmetic\n",
      "1060000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/polynomial_quotient\n",
      "Done with datasets/amps/mathematica/algebra/polynomial_quotient\n",
      "1110000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/simplify_radicals\n",
      "Done with datasets/amps/mathematica/algebra/simplify_radicals\n",
      "1120000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/simplify_radicals_w_steps\n",
      "Done with datasets/amps/mathematica/algebra/simplify_radicals_w_steps\n",
      "1125000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/function_evaluation\n",
      "Done with datasets/amps/mathematica/algebra/function_evaluation\n",
      "1175000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/system_of_equations\n",
      "Done with datasets/amps/mathematica/algebra/system_of_equations\n",
      "1225000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/invert_function\n",
      "Done with datasets/amps/mathematica/algebra/invert_function\n",
      "1235000 files read\n",
      "Loading files in datasets/amps/mathematica/algebra/complete_square_w_steps\n",
      "Done with datasets/amps/mathematica/algebra/complete_square_w_steps\n",
      "1240000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/divisible\n",
      "Done with datasets/amps/mathematica/number_theory/divisible\n",
      "1290000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/continued_fraction\n",
      "Done with datasets/amps/mathematica/number_theory/continued_fraction\n",
      "1340000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/relatively_prime\n",
      "Done with datasets/amps/mathematica/number_theory/relatively_prime\n",
      "1390000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/relatively_prime_w_steps\n",
      "Done with datasets/amps/mathematica/number_theory/relatively_prime_w_steps\n",
      "1395000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/gcd_w_steps\n",
      "Done with datasets/amps/mathematica/number_theory/gcd_w_steps\n",
      "1400000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/primitive_roots\n",
      "Done with datasets/amps/mathematica/number_theory/primitive_roots\n",
      "1410000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/factor_integer_w_steps\n",
      "Done with datasets/amps/mathematica/number_theory/factor_integer_w_steps\n",
      "1415000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/multiplicative_order\n",
      "Done with datasets/amps/mathematica/number_theory/multiplicative_order\n",
      "1465000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/totient_w_steps\n",
      "Done with datasets/amps/mathematica/number_theory/totient_w_steps\n",
      "1470000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/factor_integer\n",
      "Done with datasets/amps/mathematica/number_theory/factor_integer\n",
      "1480000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/convert_base\n",
      "Done with datasets/amps/mathematica/number_theory/convert_base\n",
      "1530000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/gcd\n",
      "Done with datasets/amps/mathematica/number_theory/gcd\n",
      "1580000 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/polygonal_number\n",
      "Done with datasets/amps/mathematica/number_theory/polygonal_number\n",
      "1580500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/lcm_w_steps\n",
      "Done with datasets/amps/mathematica/number_theory/lcm_w_steps\n",
      "1585500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/lcm\n",
      "Done with datasets/amps/mathematica/number_theory/lcm\n",
      "1635500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/power_mod\n",
      "Done with datasets/amps/mathematica/number_theory/power_mod\n",
      "1685500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/mod\n",
      "Done with datasets/amps/mathematica/number_theory/mod\n",
      "1735500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/is_prime_w_steps\n",
      "Done with datasets/amps/mathematica/number_theory/is_prime_w_steps\n",
      "1750500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/totient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with datasets/amps/mathematica/number_theory/totient\n",
      "1800500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/diophantine_equations\n",
      "Done with datasets/amps/mathematica/number_theory/diophantine_equations\n",
      "1850500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/modular_inverse\n",
      "Done with datasets/amps/mathematica/number_theory/modular_inverse\n",
      "1900500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/chinese_remainder_theorem\n",
      "Done with datasets/amps/mathematica/number_theory/chinese_remainder_theorem\n",
      "1950500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/is_prime\n",
      "Done with datasets/amps/mathematica/number_theory/is_prime\n",
      "1980500 files read\n",
      "Loading files in datasets/amps/mathematica/number_theory/convert_base_w_steps\n",
      "Done with datasets/amps/mathematica/number_theory/convert_base_w_steps\n",
      "1990500 files read\n"
     ]
    }
   ],
   "source": [
    "# Generate data to infer the rules for integral\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "from sympy import sympify, lambdify, symbols, integrate, Interval, Symbol, I, S, oo, plot, evalf, N\n",
    "from IPython.display import display\n",
    "from utils.utils import *\n",
    "\n",
    "\n",
    "sentences = []\n",
    "\n",
    "parent_folder = 'datasets/amps/mathematica/algebra'\n",
    "for folder in os.listdir(parent_folder): \n",
    "    folder_path = os.path.join(parent_folder, folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    print(\"Loading files in\", folder_path)\n",
    "    for file in os.listdir(folder_path):\n",
    "        if not file.endswith('.txt'):\n",
    "            continue\n",
    "        filepath = os.path.join(folder_path, file)\n",
    "        fin = open(filepath, 'r')\n",
    "        lines = fin.readlines()\n",
    "        sentences.append(' '.join(lines))\n",
    "        fin.close()\n",
    "    print(\"Done with\", folder_path)\n",
    "    print(len(sentences), \"files read\")\n",
    "    \n",
    "parent_folder = 'datasets/amps/mathematica/number_theory'\n",
    "for folder in os.listdir(parent_folder): \n",
    "    folder_path = os.path.join(parent_folder, folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    print(\"Loading files in\", folder_path)\n",
    "    for file in os.listdir(folder_path):\n",
    "        if not file.endswith('.txt'):\n",
    "            continue\n",
    "        filepath = os.path.join(folder_path, file)\n",
    "        fin = open(filepath, 'r')\n",
    "        lines = fin.readlines()\n",
    "        sentences.append(' '.join(lines))\n",
    "        fin.close()\n",
    "    print(\"Done with\", folder_path)\n",
    "    print(len(sentences), \"files read\")\n",
    "\n",
    "random.shuffle(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d12f7122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Saving the dataset (2/2 shards): 100%|████████████████████████████████████████████████████████████████████████████████████████████| 1976566/1976566 [00:02<00:00, 724912.03 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 13934/13934 [00:00<00:00, 705770.36 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import random\n",
    "from datasets import load_dataset, Dataset, load_from_disk\n",
    "\n",
    "random.shuffle(sentences)\n",
    "\n",
    "ds = Dataset.from_dict({'eq_pair': sentences})\n",
    "train_ds = ds.train_test_split(test_size=0.007)\n",
    "train_ds.save_to_disk(\"datasets/amps_mathematica_algebra\")\n",
    "\n",
    "#train_ds = load_from_disk(\"datasets/integrate_gptneo_dataset_50k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad73e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['eq_pair'],\n",
       "        num_rows: 1976566\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['eq_pair'],\n",
       "        num_rows: 13934\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de73e66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1976566/1976566 [02:17<00:00, 14375.37 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13934/13934 [00:00<00:00, 15659.80 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1976566/1976566 [01:54<00:00, 17197.27 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13934/13934 [00:00<00:00, 17351.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "CONTEXT_LENGTH = 256\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xhyi/PT_GPTNEO350_ATG\") #\"EleutherAI/gpt-neo-125m\") \n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"eq_pair\"], padding='max_length', truncation=True, max_length=CONTEXT_LENGTH, return_tensors=\"pt\")\n",
    "\n",
    "tokenized_ds = train_ds.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=train_ds[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    examples[\"labels\"] = examples[\"input_ids\"].copy()\n",
    "    return examples\n",
    "\n",
    "lm_dataset = tokenized_ds.map(preprocess_function, batched=True, num_proc=1)\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a35f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(lm_dataset['train'])):\n",
    "#     if len(lm_dataset['train'][i]['input_ids']) != 256:\n",
    "#         print(i, len(lm_dataset['train'][i]['input_ids']))\n",
    "#     if len(lm_dataset['train'][i]['labels']) != 256:\n",
    "#         print(i, len(lm_dataset['train'][i]['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6af69a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model0 = AutoModelForCausalLM.from_pretrained(\"xhyi/PT_GPTNEO350_ATG\")  #\"EleutherAI/gpt-neo-125m\")\n",
    "config = model0.config\n",
    "\n",
    "model = AutoModelForCausalLM.from_config(config)\n",
    "model0 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "997d4160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='988288' max='988288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [988288/988288 52:22:16, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>545000</td>\n",
       "      <td>0.402800</td>\n",
       "      <td>0.402658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550000</td>\n",
       "      <td>0.406400</td>\n",
       "      <td>0.404083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555000</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.404222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560000</td>\n",
       "      <td>0.406700</td>\n",
       "      <td>0.404368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565000</td>\n",
       "      <td>0.406100</td>\n",
       "      <td>0.404272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570000</td>\n",
       "      <td>0.407300</td>\n",
       "      <td>0.404013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575000</td>\n",
       "      <td>0.406400</td>\n",
       "      <td>0.404038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580000</td>\n",
       "      <td>0.406600</td>\n",
       "      <td>0.403994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585000</td>\n",
       "      <td>0.406200</td>\n",
       "      <td>0.404053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590000</td>\n",
       "      <td>0.406100</td>\n",
       "      <td>0.403754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595000</td>\n",
       "      <td>0.408800</td>\n",
       "      <td>0.403604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600000</td>\n",
       "      <td>0.405100</td>\n",
       "      <td>0.403378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605000</td>\n",
       "      <td>0.405500</td>\n",
       "      <td>0.402921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610000</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.402629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615000</td>\n",
       "      <td>0.404800</td>\n",
       "      <td>0.402974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620000</td>\n",
       "      <td>0.403900</td>\n",
       "      <td>0.402254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625000</td>\n",
       "      <td>0.402300</td>\n",
       "      <td>0.401934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630000</td>\n",
       "      <td>0.401600</td>\n",
       "      <td>0.401796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>635000</td>\n",
       "      <td>0.402700</td>\n",
       "      <td>0.401567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640000</td>\n",
       "      <td>0.402300</td>\n",
       "      <td>0.401274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>645000</td>\n",
       "      <td>0.400700</td>\n",
       "      <td>0.401107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650000</td>\n",
       "      <td>0.401500</td>\n",
       "      <td>0.400752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>655000</td>\n",
       "      <td>0.400700</td>\n",
       "      <td>0.400747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660000</td>\n",
       "      <td>0.400700</td>\n",
       "      <td>0.400198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>665000</td>\n",
       "      <td>0.400100</td>\n",
       "      <td>0.399951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670000</td>\n",
       "      <td>0.400200</td>\n",
       "      <td>0.399765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675000</td>\n",
       "      <td>0.400800</td>\n",
       "      <td>0.399437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680000</td>\n",
       "      <td>0.398200</td>\n",
       "      <td>0.399076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685000</td>\n",
       "      <td>0.400400</td>\n",
       "      <td>0.398752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690000</td>\n",
       "      <td>0.400400</td>\n",
       "      <td>0.398695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695000</td>\n",
       "      <td>0.395900</td>\n",
       "      <td>0.398279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700000</td>\n",
       "      <td>0.399300</td>\n",
       "      <td>0.398315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>705000</td>\n",
       "      <td>0.400500</td>\n",
       "      <td>0.398206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710000</td>\n",
       "      <td>0.399700</td>\n",
       "      <td>0.397684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715000</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>0.397359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720000</td>\n",
       "      <td>0.397700</td>\n",
       "      <td>0.396871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725000</td>\n",
       "      <td>0.397900</td>\n",
       "      <td>0.396741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730000</td>\n",
       "      <td>0.395500</td>\n",
       "      <td>0.396492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735000</td>\n",
       "      <td>0.397400</td>\n",
       "      <td>0.395844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740000</td>\n",
       "      <td>0.396100</td>\n",
       "      <td>0.395941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>745000</td>\n",
       "      <td>0.392100</td>\n",
       "      <td>0.395784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750000</td>\n",
       "      <td>0.391400</td>\n",
       "      <td>0.395490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>755000</td>\n",
       "      <td>0.391600</td>\n",
       "      <td>0.395181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760000</td>\n",
       "      <td>0.392700</td>\n",
       "      <td>0.395288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765000</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.394916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770000</td>\n",
       "      <td>0.392600</td>\n",
       "      <td>0.394647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775000</td>\n",
       "      <td>0.392200</td>\n",
       "      <td>0.394271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780000</td>\n",
       "      <td>0.392600</td>\n",
       "      <td>0.394062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>785000</td>\n",
       "      <td>0.392200</td>\n",
       "      <td>0.394025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790000</td>\n",
       "      <td>0.392700</td>\n",
       "      <td>0.393731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>795000</td>\n",
       "      <td>0.390400</td>\n",
       "      <td>0.393408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800000</td>\n",
       "      <td>0.389800</td>\n",
       "      <td>0.393365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>805000</td>\n",
       "      <td>0.389500</td>\n",
       "      <td>0.393019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810000</td>\n",
       "      <td>0.389800</td>\n",
       "      <td>0.392673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>815000</td>\n",
       "      <td>0.390800</td>\n",
       "      <td>0.392708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820000</td>\n",
       "      <td>0.390600</td>\n",
       "      <td>0.392258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825000</td>\n",
       "      <td>0.389800</td>\n",
       "      <td>0.392174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830000</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.391777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>835000</td>\n",
       "      <td>0.389300</td>\n",
       "      <td>0.391609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840000</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.391365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>845000</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.391116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850000</td>\n",
       "      <td>0.389600</td>\n",
       "      <td>0.390906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>855000</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.390582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860000</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.390519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>865000</td>\n",
       "      <td>0.388500</td>\n",
       "      <td>0.390395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870000</td>\n",
       "      <td>0.381800</td>\n",
       "      <td>0.390442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875000</td>\n",
       "      <td>0.382200</td>\n",
       "      <td>0.390354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880000</td>\n",
       "      <td>0.383200</td>\n",
       "      <td>0.390209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885000</td>\n",
       "      <td>0.381900</td>\n",
       "      <td>0.390144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890000</td>\n",
       "      <td>0.381200</td>\n",
       "      <td>0.389848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895000</td>\n",
       "      <td>0.381600</td>\n",
       "      <td>0.389774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900000</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.389810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>905000</td>\n",
       "      <td>0.383500</td>\n",
       "      <td>0.389405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910000</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>0.389309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>915000</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.389197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920000</td>\n",
       "      <td>0.379500</td>\n",
       "      <td>0.389027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925000</td>\n",
       "      <td>0.381500</td>\n",
       "      <td>0.388754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930000</td>\n",
       "      <td>0.379900</td>\n",
       "      <td>0.388711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>935000</td>\n",
       "      <td>0.382800</td>\n",
       "      <td>0.388578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940000</td>\n",
       "      <td>0.380400</td>\n",
       "      <td>0.388328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>945000</td>\n",
       "      <td>0.380100</td>\n",
       "      <td>0.388363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950000</td>\n",
       "      <td>0.381000</td>\n",
       "      <td>0.388091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>955000</td>\n",
       "      <td>0.382400</td>\n",
       "      <td>0.387949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960000</td>\n",
       "      <td>0.380700</td>\n",
       "      <td>0.387879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>965000</td>\n",
       "      <td>0.380500</td>\n",
       "      <td>0.387800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970000</td>\n",
       "      <td>0.382200</td>\n",
       "      <td>0.387651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975000</td>\n",
       "      <td>0.379500</td>\n",
       "      <td>0.387492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980000</td>\n",
       "      <td>0.379600</td>\n",
       "      <td>0.387433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>985000</td>\n",
       "      <td>0.379700</td>\n",
       "      <td>0.387372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=988288, training_loss=0.17830957895176905, metrics={'train_runtime': 188537.7749, 'train_samples_per_second': 83.869, 'train_steps_per_second': 5.242, 'total_flos': 7.34076680145784e+18, 'train_loss': 0.17830957895176905, 'epoch': 8.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"datasets/pretrain_amps_mathematica_gptneo_350m\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=1e-6,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=8,\n",
    "    fp16=True,\n",
    "    save_steps=5000,\n",
    "    eval_steps=5000,\n",
    "    logging_steps=5000,\n",
    "    save_total_limit=4,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train(\"datasets/pretrain_amps_mathematica_gptneo_350m/checkpoint-540000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4e01fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"datasets/amps_mathematica_algebra_numtheory_gptneo_350m/gptneo-350m-985000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86e06cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"datasets/integrate_gptneo_202401/gptneo-350m-5500-loss0.350.model\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f9f2e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcwave/anaconda3/envs/symbolic/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10$.\n",
      " Answer14111021^1$10}54719 x12$\n",
      " Answer:2100743$\n",
      "638231059$38_114$619$21$\n",
      "}$\n",
      "}$\n",
      "}$\n",
      "}$\n",
      "}$\n",
      "}$\n",
      "}$\n",
      "}$\n",
      "}$\n",
      "}$\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def generate_integral(input):\n",
    "    # Encode some input text\n",
    "    prompt = input + \" entail\"\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    # Generate text\n",
    "    output = model.generate(input_ids, max_length=100, num_return_sequences=1, temperature=0.7)\n",
    "    # Decode and print the output\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    #print(generated_text)\n",
    "    if 'entail' in generated_text:\n",
    "        generated_text = generated_text[generated_text.find('entail') + 6:].strip()\n",
    "        #print(generated_text)\n",
    "    if 'end' in generated_text:\n",
    "        generated_text = generated_text[0:generated_text.find('end')].strip()\n",
    "    return generated_text\n",
    "    \n",
    "print(generate_integral(\"2.5*t**3 + 0.51*t**2 + 3.2*t + 1.2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ed15bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eq_pair': 'Problem:\\n Find the sum $p(x) + q(x)$ of the following two polynomials: $p(x) = -5 x^2-11 x+11$, $q(x) = 7 x^2+8 x+1$\\n Answer:\\n $2 x^2-3 x+12$'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f981b806",
   "metadata": {},
   "outputs": [
    {
     "ename": "SympifyError",
     "evalue": "Sympify of expression 'could not parse 'Problem: Find the sum $p(x) + q(x)$ of the following two polynomials: $p(x) = -5 x^2-11 x+11$, $q(x) = 7 x^2+8 x+1$ Answer: $2 x^2-3 x+12'' failed, because of exception being raised:\nSyntaxError: invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;31mValueError\u001b[0m: Error from parse_expr with transformed code: \"Symbol ('Problem' ):Symbol ('Find' )Symbol ('the' )sum  $Function ('p' )(Symbol ('x' ))+Function ('q' )(Symbol ('x' ))$Symbol ('of' )Symbol ('the' )Symbol ('following' )Symbol ('two' )Symbol ('polynomials' ): $Function ('p' )(Symbol ('x' ))=-Integer (5 )Symbol ('x' )**Integer (2 )-Integer (11 )Symbol ('x' )+Integer (11 )$, $Function ('q' )(Symbol ('x' ))=Integer (7 )Symbol ('x' )**Integer (2 )+Integer (8 )Symbol ('x' )+Integer (1 )$Symbol ('Answer' ): $Integer (2 )Symbol ('x' )**Integer (2 )-Integer (3 )Symbol ('x' )+Integer (12 )\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/symbolic/lib/python3.10/site-packages/sympy/core/sympify.py:495\u001b[0m, in \u001b[0;36msympify\u001b[0;34m(a, locals, convert_xor, strict, rational, evaluate)\u001b[0m\n\u001b[1;32m    494\u001b[0m     a \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 495\u001b[0m     expr \u001b[38;5;241m=\u001b[39m \u001b[43mparse_expr\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (TokenError, \u001b[38;5;167;01mSyntaxError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/symbolic/lib/python3.10/site-packages/sympy/parsing/sympy_parser.py:1087\u001b[0m, in \u001b[0;36mparse_expr\u001b[0;34m(s, local_dict, transformations, global_dict, evaluate)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     local_dict[i] \u001b[38;5;241m=\u001b[39m null\n\u001b[0;32m-> 1087\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError from parse_expr with transformed code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/symbolic/lib/python3.10/site-packages/sympy/parsing/sympy_parser.py:1078\u001b[0m, in \u001b[0;36mparse_expr\u001b[0;34m(s, local_dict, transformations, global_dict, evaluate)\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1078\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[43meval_expr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;66;03m# restore neutral definitions for names\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/symbolic/lib/python3.10/site-packages/sympy/parsing/sympy_parser.py:906\u001b[0m, in \u001b[0;36meval_expr\u001b[0;34m(code, local_dict, global_dict)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;124;03mEvaluate Python code generated by ``stringify_expr``.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03mGenerally, ``parse_expr`` should be used.\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 906\u001b[0m expr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# take local objects in preference\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m expr\n",
      "\u001b[0;31mSyntaxError\u001b[0m: invalid syntax (<string>, line 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSympifyError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepeat\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m question:\n\u001b[1;32m     23\u001b[0m     question \u001b[38;5;241m=\u001b[39m question[\u001b[38;5;241m0\u001b[39m:question\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepeat\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m---> 24\u001b[0m original \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msympify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m integral \u001b[38;5;241m=\u001b[39m round_all_floats(sp\u001b[38;5;241m.\u001b[39mintegrate(original), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose: display(integral)\n",
      "File \u001b[0;32m~/anaconda3/envs/symbolic/lib/python3.10/site-packages/sympy/core/sympify.py:497\u001b[0m, in \u001b[0;36msympify\u001b[0;34m(a, locals, convert_xor, strict, rational, evaluate)\u001b[0m\n\u001b[1;32m    495\u001b[0m     expr \u001b[38;5;241m=\u001b[39m parse_expr(a, local_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlocals\u001b[39m, transformations\u001b[38;5;241m=\u001b[39mtransformations, evaluate\u001b[38;5;241m=\u001b[39mevaluate)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (TokenError, \u001b[38;5;167;01mSyntaxError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SympifyError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcould not parse \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m a, exc)\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m expr\n",
      "\u001b[0;31mSympifyError\u001b[0m: Sympify of expression 'could not parse 'Problem: Find the sum $p(x) + q(x)$ of the following two polynomials: $p(x) = -5 x^2-11 x+11$, $q(x) = 7 x^2+8 x+1$ Answer: $2 x^2-3 x+12'' failed, because of exception being raised:\nSyntaxError: invalid syntax (<string>, line 1)"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "from utils.utils import *\n",
    "\n",
    "MIN_ALLOWED_DIFF = 0.011\n",
    "\n",
    "test_ds = train_ds['test']\n",
    "\n",
    "num_processed = 0\n",
    "num_equal = 0\n",
    "num_zero_diff = 0\n",
    "num_within_allowed = 0\n",
    "t = sp.Symbol('t')\n",
    "\n",
    "verbose = False\n",
    "\n",
    "for i in range(min(len(test_ds), 1000)):\n",
    "    if verbose:\n",
    "        print(\"Case\", i, test_ds[i]['eq_pair'])\n",
    "    eq_pair = test_ds[i]['eq_pair']\n",
    "    question = eq_pair[0:eq_pair.find('entail')].strip()\n",
    "    answer = eq_pair[eq_pair.find('entail') + 6:].replace('end', '').strip()\n",
    "    if 'repeat' in question:\n",
    "        question = question[0:question.find('repeat')]\n",
    "    original = sp.sympify(question)\n",
    "    integral = round_all_floats(sp.integrate(original), 2)\n",
    "    if verbose: display(integral)\n",
    "    try:\n",
    "        pred = generate_integral(question)\n",
    "        generated = round_all_floats(sp.sympify(pred), 2)\n",
    "        if verbose: display(generated)\n",
    "    except:\n",
    "        print(\"Cannot sympify\", pred)\n",
    "        continue\n",
    "    avg_diff = get_avg_diff(integral, generated, t)\n",
    "    if verbose: print(\"avg_diff\", avg_diff)\n",
    "    num_processed += 1\n",
    "    if avg_diff <= MIN_ALLOWED_DIFF:\n",
    "        num_within_allowed += 1\n",
    "    else:\n",
    "        display(integral)\n",
    "        display(generated)\n",
    "        print(avg_diff)\n",
    "    if avg_diff <= 0.0000001:\n",
    "        num_zero_diff += 1\n",
    "    diff_expr = sp.simplify(integral-generated)\n",
    "    if verbose: display(diff_expr)\n",
    "    if diff_expr == 0:\n",
    "        if verbose: print(\"Equal\")\n",
    "        num_equal += 1\n",
    "    if i%100 == 0:\n",
    "        print(i+1, \"processed\")\n",
    "        \n",
    "print(\"num_processed\", num_processed)\n",
    "print(\"num_equal\", num_equal)\n",
    "print(\"num_zero_diff\", num_zero_diff)\n",
    "print(\"num_within_allowed\", num_within_allowed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:symbolic]",
   "language": "python",
   "name": "conda-env-symbolic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
