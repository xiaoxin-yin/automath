{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c7ec97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Creating dataset ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356057ffba67435cab49fd0c4e7aafe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde626569a79430c98a38c5857ad7b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['instruction', 'response', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1900\n",
      "})\n",
      "Dataset({\n",
      "    features: ['instruction', 'response', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 100\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "MAX_LENGTH = 680\n",
    "\n",
    "# Path to your text file\n",
    "fin = open('data/random_func_array1d_arithmetic_test.json', 'r')\n",
    "\n",
    "lines = fin.readlines()\n",
    "instructions = []\n",
    "responses = []\n",
    "\n",
    "print(\"Loading data ...\")\n",
    "for line in lines:\n",
    "    datum = json.loads(line)\n",
    "    instruction = str(datum[\"results\"]).replace(\"\\'\", '').replace('ZeroDivisionError', 'error').replace(':', '').replace(',', '')\n",
    "    response = datum[\"random_code\"]\n",
    "    for i in range(10):\n",
    "        response = response.replace('  ', ' ')\n",
    "    responses.append(response)\n",
    "    instructions.append(instruction)\n",
    "    if len(responses) % 10000 == 0:\n",
    "        print(len(responses), \"lines loaded\")\n",
    "\n",
    "print(\"Creating dataset ...\")\n",
    "# Create a DataFrame and then a Dataset\n",
    "data = {\"instruction\": instructions, \"response\": responses}\n",
    "df = pd.DataFrame(data)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "train_test_split = dataset.train_test_split(test_size=0.05, seed=42)  # 5% for test, 95% for train\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xhyi/PT_GPTNEO350_ATG\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set the padding token\n",
    "eos_encoded = tokenizer.encode(tokenizer.eos_token)[0]\n",
    "\n",
    "# Tokenize and process the dataset\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the concatenated instruction and response\n",
    "    tokenized_data = tokenizer([instruction + \" \" + response for instruction, response in zip(examples[\"instruction\"], examples[\"response\"])], truncation=True, add_special_tokens=True, padding=\"max_length\", max_length=MAX_LENGTH)\n",
    "\n",
    "    # Create labels with -100 for the instruction part and token IDs for the response part\n",
    "    labels = []\n",
    "    for i, (instruction, response) in enumerate(zip(examples[\"instruction\"], examples[\"response\"])):\n",
    "        instruction_ids = tokenizer(instruction, add_special_tokens=False)[\"input_ids\"]\n",
    "        response_ids = tokenizer(response, add_special_tokens=False)[\"input_ids\"]\n",
    "        #print(len(instruction_ids) + len(response_ids))\n",
    "        label = [-100] * len(instruction_ids) + response_ids + [eos_encoded] + [-100] * (len(tokenized_data[\"input_ids\"][i]) - len(instruction_ids) - len(response_ids) - 1)\n",
    "        label = label[0:MAX_LENGTH]\n",
    "        labels.append(label)\n",
    "\n",
    "    # Update the tokenized_data with labels\n",
    "    tokenized_data[\"labels\"] = labels\n",
    "    return tokenized_data\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# The tokenized_dataset now contains input_ids, attention_mask, and labels\n",
    "print(tokenized_train_dataset)\n",
    "print(tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "105f3ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_train_dataset.save_to_disk('data/random_func_array1d_arithmetic_train_tokenized_v1.dataset')\n",
    "#tokenized_test_dataset.save_to_disk('data/random_func_array1d_arithmetic_test_tokenized_v1.dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d81ba1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 90, 15414, 25915, 1065, 513, 60, 5072, 532, 1065, 92, 1391, 15414, 685, 1954, 532, 19, 532, 18, 532, 1415, 352, 60, 5072, 532, 18, 92, 1391, 15414, 25915, 1065, 532, 20, 532, 1415, 1105, 60, 5072, 532, 20, 92, 1391, 15414, 685, 21, 532, 2624, 718, 604, 1367, 60, 5072, 718, 92, 1391, 15414, 685, 16, 532, 19, 604, 60, 5072, 352, 92, 1391, 15414, 25915, 17, 718, 60, 5072, 532, 17, 92, 1391, 15414, 25915, 1238, 532, 16, 860, 604, 513, 513, 532, 1065, 60, 5072, 513, 92, 1391, 15414, 25915, 16, 532, 19, 860, 642, 60, 5072, 532, 19, 92, 1391, 15414, 25915, 17, 532, 20, 532, 22, 678, 657, 60, 5072, 532, 22, 92, 1391, 15414, 685, 23, 513, 532, 16, 1478, 532, 16, 60, 5072, 532, 16, 92, 1391, 15414, 25915, 16, 532, 1314, 352, 532, 1238, 513, 2808, 532, 20, 60, 5072, 513, 92, 1391, 15414, 685, 1065, 657, 1105, 1367, 532, 17, 532, 22, 532, 17, 513, 60, 5072, 532, 22, 92, 1391, 15414, 685, 18, 352, 657, 1987, 60, 5072, 352, 92, 1391, 15414, 25915, 1485, 657, 642, 2681, 532, 21, 532, 23, 362, 532, 16, 60, 5072, 532, 23, 92, 1391, 15414, 685, 17, 1367, 532, 16, 532, 1558, 532, 1485, 60, 5072, 532, 16, 92, 1391, 15414, 685, 1120, 1105, 532, 18, 807, 532, 21, 1467, 60, 5072, 807, 92, 1391, 15414, 25915, 18, 352, 362, 532, 1129, 532, 2075, 352, 807, 532, 20, 60, 5072, 352, 92, 1391, 15414, 25915, 1129, 1511, 1315, 2608, 1367, 657, 532, 17, 532, 19, 60, 5072, 657, 92, 1391, 15414, 25915, 16, 532, 1314, 60, 5072, 532, 16, 92, 1391, 15414, 25915, 1129, 513, 838, 1367, 657, 532, 22, 60, 5072, 1367, 92, 1391, 15414, 25915, 16, 532, 1238, 532, 3132, 532, 1065, 532, 1314, 657, 60, 5072, 532, 1065, 92, 1391, 15414, 25915, 21, 807, 1467, 532, 21, 657, 60, 5072, 1467, 92, 1391, 15414, 685, 22, 718, 860, 532, 16, 532, 16, 60, 5072, 860, 92, 1391, 15414, 25915, 22, 604, 657, 657, 60, 5072, 604, 92, 1391, 15414, 685, 1959, 352, 352, 532, 1415, 718, 2242, 532, 940, 60, 5072, 718, 92, 1391, 15414, 25915, 1065, 657, 532, 1415, 532, 20, 362, 678, 513, 513, 60, 5072, 678, 92, 1391, 15414, 25915, 2623, 532, 1983, 513, 532, 16, 532, 16, 60, 5072, 513, 92, 1391, 15414, 25915, 22, 860, 532, 1485, 642, 532, 1065, 60, 5072, 532, 1485, 92, 1391, 15414, 685, 21, 642, 532, 1507, 532, 21, 532, 19, 60, 5072, 532, 1507, 92, 1391, 15414, 25915, 16, 1511, 532, 21, 513, 60, 5072, 1511, 92, 1391, 15414, 685, 22, 532, 20, 532, 16, 532, 22, 532, 19, 532, 19, 532, 18, 60, 5072, 532, 19, 92, 1391, 15414, 25915, 22, 2534, 532, 17, 1511, 532, 17, 657, 60, 5072, 1511, 92, 1391, 15414, 685, 15, 532, 18, 532, 940, 362, 60, 5072, 532, 18, 92, 1391, 15414, 685, 15, 532, 21, 532, 17, 362, 532, 1157, 1367, 2242, 678, 60, 5072, 1367, 92, 1391, 15414, 25915, 23, 352, 838, 60, 5072, 532, 23, 92, 1391, 15414, 685, 21, 2319, 5014, 532, 18, 532, 24, 532, 18, 532, 940, 60, 5072, 532, 24, 92, 1391, 15414, 685, 1558, 532, 18, 657, 532, 18, 60, 5072, 532, 18, 92, 1391, 15414, 685, 1433, 532, 21, 60, 5072, 1467, 92, 1391, 15414, 685, 19, 352, 532, 3132, 5946, 532, 20, 60, 5072, 532, 3132, 92, 1391, 15414, 25915, 1495, 513, 1478, 60, 5072, 532, 1495, 92, 60, 825, 22944, 7, 3258, 2599, 198, 611, 18896, 7, 3258, 8, 6624, 352, 25, 198, 1441, 5240, 58, 15, 60, 198, 2073, 25, 198, 611, 18896, 7, 3258, 8, 19841, 513, 25, 198, 1441, 5240, 58, 15, 60, 198, 2073, 25, 198, 1441, 22944, 7, 3258, 58, 16, 25, 12962, 198, 220]\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 4299, 22944, 7, 3258, 2599, 198, 611, 18896, 7, 3258, 8, 6624, 352, 25, 198, 1441, 5240, 58, 15, 60, 198, 2073, 25, 198, 611, 18896, 7, 3258, 8, 19841, 513, 25, 198, 1441, 5240, 58, 15, 60, 198, 2073, 25, 198, 1441, 22944, 7, 3258, 58, 16, 25, 12962, 198, 220, 50256, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ],
   "source": [
    "x = tokenized_train_dataset[0]\n",
    "\n",
    "ids = x[\"input_ids\"]\n",
    "labels = x[\"labels\"]\n",
    "ids_idx = 0\n",
    "while ids[ids_idx] != 50256:\n",
    "    ids_idx+=1\n",
    "print(ids[:ids_idx])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c7f7d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{input [9 8 14] output 1} {input [2 5 4 -10 11 60] output 5} {input [-1 -2] output 1} {input [-15 -2 6 -1 4 8 1 -4] output 6} {input [-3 -5] output 2} {input [-12 -5 -2 6] output -1} {input [0 -10 0 5 15] output -8} {input [-4 -3 -9 -14 -2 -3 -9 3] output -4} {input [27 1 -3 1 -6 6] output 3} {input [-5 -5 -5 -1 -7 -8 8] output 11} {input [-20 10] output -2} {input [8 -5 20 1 -6 2 1 0] output 0} {input [-4 10 1 3] output -2} {input [8 1] output 0} {input [9 -13 4] output 5} {input [-9 -2 6 3 6] output 9} {input [-10 -5] output 2} {input [-34 4 4] output 1} {input [-17 -17 1] output 1} {input [20 14 3 -2 -12] output 6} {input [-3 -10 16 -13 15 -2] output 7} {input [0 -7 2 11 3 -5 5] output -4} {input [10 2 0 -3 3] output 0} {input [-13 -1 13 4 -34] output -2} {input [2 -1 18 15] output -1} {input [-1 0 -1 2] output 10} {input [18 4 2] output 2} {input [-1 -3] output 2} {input [4 1 12 2 6 -12 5 2] output -2} {input [14 -7 -5 -2 -9] output 2} {input [-2 27 -4 0 -9 -2 -27] output 1} {input [11 -6 20 -1 -4] output 6} {input [3 -3 1 -6 5 8 9] output -3} {input [1 20 2] output -3} {input [-6 -6 5 -6 -13 3] output -1} {input [-2 9] output 3} {input [12 -22 5 -1] output -2} {input [11 -2 -26 -1 2 -8] output 13} {input [-16 -22 33 7] output 4} {input [-6 5 -2 6 -9 -2 -6 -1] output 7}] def foo(arr):\n",
      " if len(arr) == 1:\n",
      " return (arr[0] % 7)\n",
      " else:\n",
      " if len(arr)!= 6:\n",
      " return (arr[0] % 7) - foo(arr[1:])\n",
      " else:\n",
      " return foo(arr[1:])\n",
      " <|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "680\n",
      "ids 0 58 [\n",
      "ids 1 90 {\n",
      "ids 2 15414 input\n",
      "ids 3 25915  [-\n",
      "ids 4 18 3\n",
      "ids 5 657  0\n",
      "ids 6 657  0\n",
      "ids 7 60 ]\n",
      "ids 8 5072  output\n",
      "ids 9 532  -\n",
      "ids 10 18 3\n",
      "ids 11 92 }\n",
      "ids 12 1391  {\n",
      "ids 13 15414 input\n",
      "ids 14 25915  [-\n",
      "ids 15 1983 27\n",
      "ids 16 532  -\n",
      "ids 17 18 3\n",
      "ids 18 532  -\n",
      "ids 19 1314 15\n",
      "ids 20 1105  12\n",
      "ids 21 807  8\n",
      "ids 22 532  -\n",
      "ids 23 20 5\n",
      "ids 24 1511  13\n",
      "ids 25 532  -\n",
      "ids 26 18 3\n",
      "ids 27 60 ]\n",
      "ids 28 5072  output\n",
      "ids 29 532  -\n",
      "ids 30 1314 15\n",
      "ids 31 92 }\n",
      "ids 32 1391  {\n",
      "ids 33 15414 input\n",
      "ids 34 25915  [-\n",
      "ids 35 1129 19\n",
      "ids 36 532  -\n",
      "ids 37 23 8\n",
      "ids 38 657  0\n",
      "ids 39 532  -\n",
      "ids 40 24 9\n",
      "ids 41 532  -\n",
      "ids 42 23 8\n",
      "ids 43 60 ]\n",
      "ids 44 5072  output\n",
      "ids 45 532  -\n",
      "ids 46 1129 19\n",
      "ids 47 92 }\n",
      "ids 48 1391  {\n",
      "ids 49 15414 input\n",
      "ids 50 25915  [-\n",
      "ids 51 19 4\n",
      "ids 52 1367  11\n",
      "ids 53 532  -\n",
      "ids 54 16 1\n",
      "ids 55 60 ]\n",
      "ids 56 5072  output\n",
      "ids 57 532  -\n",
      "ids 58 19 4\n",
      "ids 59 92 }\n",
      "ids 60 1391  {\n",
      "ids 61 15414 input\n",
      "ids 62 685  [\n",
      "ids 63 1157 11\n",
      "ids 64 532  -\n",
      "ids 65 1415 14\n",
      "ids 66 532  -\n",
      "ids 67 23 8\n",
      "ids 68 642  5\n",
      "ids 69 60 ]\n",
      "ids 70 5072  output\n",
      "ids 71 1367  11\n",
      "ids 72 92 }\n",
      "ids 73 1391  {\n",
      "ids 74 15414 input\n",
      "ids 75 25915  [-\n",
      "ids 76 18 3\n",
      "ids 77 532  -\n",
      "ids 78 24 9\n",
      "ids 79 860  9\n",
      "ids 80 352  1\n",
      "ids 81 532  -\n",
      "ids 82 23 8\n",
      "ids 83 657  0\n",
      "ids 84 657  0\n",
      "ids 85 532  -\n",
      "ids 86 19 4\n",
      "ids 87 60 ]\n",
      "ids 88 5072  output\n",
      "ids 89 860  9\n",
      "ids 90 92 }\n",
      "ids 91 1391  {\n",
      "ids 92 15414 input\n",
      "ids 93 25915  [-\n",
      "ids 94 1314 15\n",
      "ids 95 532  -\n",
      "ids 96 18 3\n",
      "ids 97 532  -\n",
      "ids 98 23 8\n",
      "ids 99 604  4\n",
      "ids 100 2310  21\n",
      "ids 101 532  -\n",
      "ids 102 16 1\n",
      "ids 103 532  -\n",
      "ids 104 24 9\n",
      "ids 105 60 ]\n",
      "ids 106 5072  output\n",
      "ids 107 532  -\n",
      "ids 108 18 3\n",
      "ids 109 92 }\n",
      "ids 110 1391  {\n",
      "ids 111 15414 input\n",
      "ids 112 25915  [-\n",
      "ids 113 1129 19\n",
      "ids 114 4974  34\n",
      "ids 115 362  2\n",
      "ids 116 532  -\n",
      "ids 117 18 3\n",
      "ids 118 532  -\n",
      "ids 119 20 5\n",
      "ids 120 352  1\n",
      "ids 121 60 ]\n",
      "ids 122 5072  output\n",
      "ids 123 532  -\n",
      "ids 124 1129 19\n",
      "ids 125 92 }\n",
      "ids 126 1391  {\n",
      "ids 127 15414 input\n",
      "ids 128 685  [\n",
      "ids 129 2624 32\n",
      "ids 130 532  -\n",
      "ids 131 1238 20\n",
      "ids 132 513  3\n",
      "ids 133 362  2\n",
      "ids 134 532  -\n",
      "ids 135 23 8\n",
      "ids 136 60 ]\n",
      "ids 137 5072  output\n",
      "ids 138 3933  32\n",
      "ids 139 92 }\n",
      "ids 140 1391  {\n",
      "ids 141 15414 input\n",
      "ids 142 25915  [-\n",
      "ids 143 17 2\n",
      "ids 144 532  -\n",
      "ids 145 1954 23\n",
      "ids 146 532  -\n",
      "ids 147 16 1\n",
      "ids 148 362  2\n",
      "ids 149 532  -\n",
      "ids 150 24 9\n",
      "ids 151 60 ]\n",
      "ids 152 5072  output\n",
      "ids 153 532  -\n",
      "ids 154 17 2\n",
      "ids 155 92 }\n",
      "ids 156 1391  {\n",
      "ids 157 15414 input\n",
      "ids 158 685  [\n",
      "ids 159 1238 20\n",
      "ids 160 532  -\n",
      "ids 161 18 3\n",
      "ids 162 532  -\n",
      "ids 163 1415 14\n",
      "ids 164 362  2\n",
      "ids 165 532  -\n",
      "ids 166 2075 26\n",
      "ids 167 532  -\n",
      "ids 168 1129 19\n",
      "ids 169 60 ]\n",
      "ids 170 5072  output\n",
      "ids 171 1160  20\n",
      "ids 172 92 }\n",
      "ids 173 1391  {\n",
      "ids 174 15414 input\n",
      "ids 175 685  [\n",
      "ids 176 940 10\n",
      "ids 177 532  -\n",
      "ids 178 940 10\n",
      "ids 179 532  -\n",
      "ids 180 1314 15\n",
      "ids 181 532  -\n",
      "ids 182 19 4\n",
      "ids 183 362  2\n",
      "ids 184 60 ]\n",
      "ids 185 5072  output\n",
      "ids 186 838  10\n",
      "ids 187 92 }\n",
      "ids 188 1391  {\n",
      "ids 189 15414 input\n",
      "ids 190 25915  [-\n",
      "ids 191 18 3\n",
      "ids 192 532  -\n",
      "ids 193 1314 15\n",
      "ids 194 532  -\n",
      "ids 195 1314 15\n",
      "ids 196 60 ]\n",
      "ids 197 5072  output\n",
      "ids 198 532  -\n",
      "ids 199 18 3\n",
      "ids 200 92 }\n",
      "ids 201 1391  {\n",
      "ids 202 15414 input\n",
      "ids 203 25915  [-\n",
      "ids 204 24 9\n",
      "ids 205 532  -\n",
      "ids 206 16 1\n",
      "ids 207 532  -\n",
      "ids 208 24 9\n",
      "ids 209 362  2\n",
      "ids 210 60 ]\n",
      "ids 211 5072  output\n",
      "ids 212 532  -\n",
      "ids 213 24 9\n",
      "ids 214 92 }\n",
      "ids 215 1391  {\n",
      "ids 216 15414 input\n",
      "ids 217 25915  [-\n",
      "ids 218 23 8\n",
      "ids 219 532  -\n",
      "ids 220 1828 22\n",
      "ids 221 352  1\n",
      "ids 222 1467  16\n",
      "ids 223 532  -\n",
      "ids 224 24 9\n",
      "ids 225 642  5\n",
      "ids 226 532  -\n",
      "ids 227 20 5\n",
      "ids 228 60 ]\n",
      "ids 229 5072  output\n",
      "ids 230 532  -\n",
      "ids 231 1828 22\n",
      "ids 232 92 }\n",
      "ids 233 1391  {\n",
      "ids 234 15414 input\n",
      "ids 235 25915  [-\n",
      "ids 236 21 6\n",
      "ids 237 657  0\n",
      "ids 238 642  5\n",
      "ids 239 60 ]\n",
      "ids 240 5072  output\n",
      "ids 241 532  -\n",
      "ids 242 21 6\n",
      "ids 243 92 }\n",
      "ids 244 1391  {\n",
      "ids 245 15414 input\n",
      "ids 246 25915  [-\n",
      "ids 247 1731 24\n",
      "ids 248 767  7\n",
      "ids 249 362  2\n",
      "ids 250 60 ]\n",
      "ids 251 5072  output\n",
      "ids 252 532  -\n",
      "ids 253 1731 24\n",
      "ids 254 92 }\n",
      "ids 255 1391  {\n",
      "ids 256 15414 input\n",
      "ids 257 685  [\n",
      "ids 258 19 4\n",
      "ids 259 657  0\n",
      "ids 260 718  6\n",
      "ids 261 604  4\n",
      "ids 262 532  -\n",
      "ids 263 17 2\n",
      "ids 264 362  2\n",
      "ids 265 60 ]\n",
      "ids 266 5072  output\n",
      "ids 267 604  4\n",
      "ids 268 92 }\n",
      "ids 269 1391  {\n",
      "ids 270 15414 input\n",
      "ids 271 25915  [-\n",
      "ids 272 1238 20\n",
      "ids 273 532  -\n",
      "ids 274 20 5\n",
      "ids 275 60 ]\n",
      "ids 276 5072  output\n",
      "ids 277 532  -\n",
      "ids 278 1238 20\n",
      "ids 279 92 }\n",
      "ids 280 1391  {\n",
      "ids 281 15414 input\n",
      "ids 282 25915  [-\n",
      "ids 283 19 4\n",
      "ids 284 532  -\n",
      "ids 285 17 2\n",
      "ids 286 532  -\n",
      "ids 287 20 5\n",
      "ids 288 1679  25\n",
      "ids 289 532  -\n",
      "ids 290 1157 11\n",
      "ids 291 838  10\n",
      "ids 292 1478  14\n",
      "ids 293 60 ]\n",
      "ids 294 5072  output\n",
      "ids 295 532  -\n",
      "ids 296 17 2\n",
      "ids 297 92 }\n",
      "ids 298 1391  {\n",
      "ids 299 15414 input\n",
      "ids 300 25915  [-\n",
      "ids 301 1433 16\n",
      "ids 302 1467  16\n",
      "ids 303 532  -\n",
      "ids 304 1238 20\n",
      "ids 305 60 ]\n",
      "ids 306 5072  output\n",
      "ids 307 532  -\n",
      "ids 308 1433 16\n",
      "ids 309 92 }\n",
      "ids 310 1391  {\n",
      "ids 311 15414 input\n",
      "ids 312 25915  [-\n",
      "ids 313 18 3\n",
      "ids 314 532  -\n",
      "ids 315 16 1\n",
      "ids 316 532  -\n",
      "ids 317 16 1\n",
      "ids 318 532  -\n",
      "ids 319 16 1\n",
      "ids 320 718  6\n",
      "ids 321 767  7\n",
      "ids 322 532  -\n",
      "ids 323 19 4\n",
      "ids 324 513  3\n",
      "ids 325 60 ]\n",
      "ids 326 5072  output\n",
      "ids 327 532  -\n",
      "ids 328 16 1\n",
      "ids 329 92 }\n",
      "ids 330 1391  {\n",
      "ids 331 15414 input\n",
      "ids 332 685  [\n",
      "ids 333 1821 40\n",
      "ids 334 532  -\n",
      "ids 335 24 9\n",
      "ids 336 532  -\n",
      "ids 337 17 2\n",
      "ids 338 532  -\n",
      "ids 339 19 4\n",
      "ids 340 513  3\n",
      "ids 341 352  1\n",
      "ids 342 532  -\n",
      "ids 343 16 1\n",
      "ids 344 657  0\n",
      "ids 345 60 ]\n",
      "ids 346 5072  output\n",
      "ids 347 532  -\n",
      "ids 348 17 2\n",
      "ids 349 92 }\n",
      "ids 350 1391  {\n",
      "ids 351 15414 input\n",
      "ids 352 25915  [-\n",
      "ids 353 19 4\n",
      "ids 354 362  2\n",
      "ids 355 60 ]\n",
      "ids 356 5072  output\n",
      "ids 357 532  -\n",
      "ids 358 19 4\n",
      "ids 359 92 }\n",
      "ids 360 1391  {\n",
      "ids 361 15414 input\n",
      "ids 362 685  [\n",
      "ids 363 1238 20\n",
      "ids 364 532  -\n",
      "ids 365 18 3\n",
      "ids 366 532  -\n",
      "ids 367 940 10\n",
      "ids 368 532  -\n",
      "ids 369 22 7\n",
      "ids 370 60 ]\n",
      "ids 371 5072  output\n",
      "ids 372 1160  20\n",
      "ids 373 92 }\n",
      "ids 374 1391  {\n",
      "ids 375 15414 input\n",
      "ids 376 25915  [-\n",
      "ids 377 23 8\n",
      "ids 378 362  2\n",
      "ids 379 513  3\n",
      "ids 380 718  6\n",
      "ids 381 60 ]\n",
      "ids 382 5072  output\n",
      "ids 383 532  -\n",
      "ids 384 23 8\n",
      "ids 385 92 }\n",
      "ids 386 1391  {\n",
      "ids 387 15414 input\n",
      "ids 388 25915  [-\n",
      "ids 389 1157 11\n",
      "ids 390 1511  13\n",
      "ids 391 352  1\n",
      "ids 392 1467  16\n",
      "ids 393 532  -\n",
      "ids 394 22 7\n",
      "ids 395 604  4\n",
      "ids 396 532  -\n",
      "ids 397 18 3\n",
      "ids 398 532  -\n",
      "ids 399 2548 38\n",
      "ids 400 60 ]\n",
      "ids 401 5072  output\n",
      "ids 402 352  1\n",
      "ids 403 92 }\n",
      "ids 404 1391  {\n",
      "ids 405 15414 input\n",
      "ids 406 25915  [-\n",
      "ids 407 1485 13\n",
      "ids 408 838  10\n",
      "ids 409 642  5\n",
      "ids 410 532  -\n",
      "ids 411 1485 13\n",
      "ids 412 532  -\n",
      "ids 413 20 5\n",
      "ids 414 657  0\n",
      "ids 415 532  -\n",
      "ids 416 16 1\n",
      "ids 417 60 ]\n",
      "ids 418 5072  output\n",
      "ids 419 838  10\n",
      "ids 420 92 }\n",
      "ids 421 1391  {\n",
      "ids 422 15414 input\n",
      "ids 423 685  [\n",
      "ids 424 23 8\n",
      "ids 425 532  -\n",
      "ids 426 940 10\n",
      "ids 427 60 ]\n",
      "ids 428 5072  output\n",
      "ids 429 807  8\n",
      "ids 430 92 }\n",
      "ids 431 1391  {\n",
      "ids 432 15414 input\n",
      "ids 433 25915  [-\n",
      "ids 434 21 6\n",
      "ids 435 642  5\n",
      "ids 436 60 ]\n",
      "ids 437 5072  output\n",
      "ids 438 532  -\n",
      "ids 439 21 6\n",
      "ids 440 92 }\n",
      "ids 441 1391  {\n",
      "ids 442 15414 input\n",
      "ids 443 685  [\n",
      "ids 444 17 2\n",
      "ids 445 532  -\n",
      "ids 446 1507 18\n",
      "ids 447 532  -\n",
      "ids 448 24 9\n",
      "ids 449 532  -\n",
      "ids 450 940 10\n",
      "ids 451 1248  18\n",
      "ids 452 513  3\n",
      "ids 453 60 ]\n",
      "ids 454 5072  output\n",
      "ids 455 362  2\n",
      "ids 456 92 }\n",
      "ids 457 1391  {\n",
      "ids 458 15414 input\n",
      "ids 459 25915  [-\n",
      "ids 460 16 1\n",
      "ids 461 2681  27\n",
      "ids 462 532  -\n",
      "ids 463 22 7\n",
      "ids 464 352  1\n",
      "ids 465 767  7\n",
      "ids 466 532  -\n",
      "ids 467 1157 11\n",
      "ids 468 60 ]\n",
      "ids 469 5072  output\n",
      "ids 470 532  -\n",
      "ids 471 16 1\n",
      "ids 472 92 }\n",
      "ids 473 1391  {\n",
      "ids 474 15414 input\n",
      "ids 475 685  [\n",
      "ids 476 940 10\n",
      "ids 477 1367  11\n",
      "ids 478 1511  13\n",
      "ids 479 60 ]\n",
      "ids 480 5072  output\n",
      "ids 481 838  10\n",
      "ids 482 92 }\n",
      "ids 483 1391  {\n",
      "ids 484 15414 input\n",
      "ids 485 25915  [-\n",
      "ids 486 24 9\n",
      "ids 487 532  -\n",
      "ids 488 21 6\n",
      "ids 489 362  2\n",
      "ids 490 3439  35\n",
      "ids 491 532  -\n",
      "ids 492 21 6\n",
      "ids 493 657  0\n",
      "ids 494 532  -\n",
      "ids 495 1954 23\n",
      "ids 496 60 ]\n",
      "ids 497 5072  output\n",
      "ids 498 532  -\n",
      "ids 499 21 6\n",
      "ids 500 92 }\n",
      "ids 501 1391  {\n",
      "ids 502 15414 input\n",
      "ids 503 25915  [-\n",
      "ids 504 1433 16\n",
      "ids 505 767  7\n",
      "ids 506 532  -\n",
      "ids 507 1314 15\n",
      "ids 508 362  2\n",
      "ids 509 1467  16\n",
      "ids 510 1367  11\n",
      "ids 511 1105  12\n",
      "ids 512 60 ]\n",
      "ids 513 5072  output\n",
      "ids 514 767  7\n",
      "ids 515 92 }\n",
      "ids 516 1391  {\n",
      "ids 517 15414 input\n",
      "ids 518 685  [\n",
      "ids 519 19 4\n",
      "ids 520 1596  17\n",
      "ids 521 532  -\n",
      "ids 522 24 9\n",
      "ids 523 532  -\n",
      "ids 524 18 3\n",
      "ids 525 532  -\n",
      "ids 526 1157 11\n",
      "ids 527 60 ]\n",
      "ids 528 5072  output\n",
      "ids 529 604  4\n",
      "ids 530 92 }\n",
      "ids 531 1391  {\n",
      "ids 532 15414 input\n",
      "ids 533 25915  [-\n",
      "ids 534 1828 22\n",
      "ids 535 362  2\n",
      "ids 536 60 ]\n",
      "ids 537 5072  output\n",
      "ids 538 532  -\n",
      "ids 539 1828 22\n",
      "ids 540 92 }\n",
      "ids 541 1391  {\n",
      "ids 542 15414 input\n",
      "ids 543 685  [\n",
      "ids 544 24 9\n",
      "ids 545 532  -\n",
      "ids 546 1065 12\n",
      "ids 547 532  -\n",
      "ids 548 20 5\n",
      "ids 549 807  8\n",
      "ids 550 532  -\n",
      "ids 551 2481 21\n",
      "ids 552 532  -\n",
      "ids 553 20 5\n",
      "ids 554 513  3\n",
      "ids 555 60 ]\n",
      "ids 556 5072  output\n",
      "ids 557 532  -\n",
      "ids 558 1065 12\n",
      "ids 559 92 }\n",
      "ids 560 1391  {\n",
      "ids 561 15414 input\n",
      "ids 562 685  [\n",
      "ids 563 20 5\n",
      "ids 564 532  -\n",
      "ids 565 1065 12\n",
      "ids 566 532  -\n",
      "ids 567 24 9\n",
      "ids 568 60 ]\n",
      "ids 569 5072  output\n",
      "ids 570 642  5\n",
      "ids 571 92 }\n",
      "ids 572 1391  {\n",
      "ids 573 15414 input\n",
      "ids 574 685  [\n",
      "ids 575 23 8\n",
      "ids 576 513  3\n",
      "ids 577 352  1\n",
      "ids 578 532  -\n",
      "ids 579 16 1\n",
      "ids 580 678  19\n",
      "ids 581 60 ]\n",
      "ids 582 5072  output\n",
      "ids 583 807  8\n",
      "ids 584 92 }\n",
      "ids 585 60 ]\n",
      "ids 586 825  def\n",
      "labels 586 4299 def\n",
      "ids 587 22944  foo\n",
      "labels 587 22944  foo\n",
      "ids 588 7 (\n",
      "labels 588 7 (\n",
      "ids 589 3258 arr\n",
      "labels 589 3258 arr\n",
      "ids 590 2599 ):\n",
      "labels 590 2599 ):\n",
      "ids 591 198 \n",
      "\n",
      "labels 591 198 \n",
      "\n",
      "ids 592 611  if\n",
      "labels 592 611  if\n",
      "ids 593 18896  len\n",
      "labels 593 18896  len\n",
      "ids 594 7 (\n",
      "labels 594 7 (\n",
      "ids 595 3258 arr\n",
      "labels 595 3258 arr\n",
      "ids 596 8 )\n",
      "labels 596 8 )\n",
      "ids 597 6624  ==\n",
      "labels 597 6624  ==\n",
      "ids 598 352  1\n",
      "labels 598 352  1\n",
      "ids 599 25 :\n",
      "labels 599 25 :\n",
      "ids 600 198 \n",
      "\n",
      "labels 600 198 \n",
      "\n",
      "ids 601 1441  return\n",
      "labels 601 1441  return\n",
      "ids 602 2352  abs\n",
      "labels 602 2352  abs\n",
      "ids 603 7 (\n",
      "labels 603 7 (\n",
      "ids 604 3258 arr\n",
      "labels 604 3258 arr\n",
      "ids 605 58 [\n",
      "labels 605 58 [\n",
      "ids 606 15 0\n",
      "labels 606 15 0\n",
      "ids 607 12962 ])\n",
      "labels 607 12962 ])\n",
      "ids 608 198 \n",
      "\n",
      "labels 608 198 \n",
      "\n",
      "ids 609 2073  else\n",
      "labels 609 2073  else\n",
      "ids 610 25 :\n",
      "labels 610 25 :\n",
      "ids 611 198 \n",
      "\n",
      "labels 611 198 \n",
      "\n",
      "ids 612 611  if\n",
      "labels 612 611  if\n",
      "ids 613 18896  len\n",
      "labels 613 18896  len\n",
      "ids 614 7 (\n",
      "labels 614 7 (\n",
      "ids 615 3258 arr\n",
      "labels 615 3258 arr\n",
      "ids 616 8 )\n",
      "labels 616 8 )\n",
      "ids 617 1279  <\n",
      "labels 617 1279  <\n",
      "ids 618 767  7\n",
      "labels 618 767  7\n",
      "ids 619 25 :\n",
      "labels 619 25 :\n",
      "ids 620 198 \n",
      "\n",
      "labels 620 198 \n",
      "\n",
      "ids 621 1441  return\n",
      "labels 621 1441  return\n",
      "ids 622 5240  arr\n",
      "labels 622 5240  arr\n",
      "ids 623 58 [\n",
      "labels 623 58 [\n",
      "ids 624 15 0\n",
      "labels 624 15 0\n",
      "ids 625 60 ]\n",
      "labels 625 60 ]\n",
      "ids 626 198 \n",
      "\n",
      "labels 626 198 \n",
      "\n",
      "ids 627 2073  else\n",
      "labels 627 2073  else\n",
      "ids 628 25 :\n",
      "labels 628 25 :\n",
      "ids 629 198 \n",
      "\n",
      "labels 629 198 \n",
      "\n",
      "ids 630 1441  return\n",
      "labels 630 1441  return\n",
      "ids 631 22944  foo\n",
      "labels 631 22944  foo\n",
      "ids 632 7 (\n",
      "labels 632 7 (\n",
      "ids 633 3258 arr\n",
      "labels 633 3258 arr\n",
      "ids 634 58 [\n",
      "labels 634 58 [\n",
      "ids 635 16 1\n",
      "labels 635 16 1\n",
      "ids 636 25 :\n",
      "labels 636 25 :\n",
      "ids 637 12962 ])\n",
      "labels 637 12962 ])\n",
      "ids 638 198 \n",
      "\n",
      "labels 638 198 \n",
      "\n",
      "ids 639 220  \n",
      "labels 639 220  \n",
      "ids 640 50256 <|endoftext|>\n",
      "labels 640 50256 <|endoftext|>\n",
      "ids 641 50256 <|endoftext|>\n",
      "ids 642 50256 <|endoftext|>\n",
      "ids 643 50256 <|endoftext|>\n",
      "ids 644 50256 <|endoftext|>\n",
      "ids 645 50256 <|endoftext|>\n",
      "ids 646 50256 <|endoftext|>\n",
      "ids 647 50256 <|endoftext|>\n",
      "ids 648 50256 <|endoftext|>\n",
      "ids 649 50256 <|endoftext|>\n",
      "ids 650 50256 <|endoftext|>\n",
      "ids 651 50256 <|endoftext|>\n",
      "ids 652 50256 <|endoftext|>\n",
      "ids 653 50256 <|endoftext|>\n",
      "ids 654 50256 <|endoftext|>\n",
      "ids 655 50256 <|endoftext|>\n",
      "ids 656 50256 <|endoftext|>\n",
      "ids 657 50256 <|endoftext|>\n",
      "ids 658 50256 <|endoftext|>\n",
      "ids 659 50256 <|endoftext|>\n",
      "ids 660 50256 <|endoftext|>\n",
      "ids 661 50256 <|endoftext|>\n",
      "ids 662 50256 <|endoftext|>\n",
      "ids 663 50256 <|endoftext|>\n",
      "ids 664 50256 <|endoftext|>\n",
      "ids 665 50256 <|endoftext|>\n",
      "ids 666 50256 <|endoftext|>\n",
      "ids 667 50256 <|endoftext|>\n",
      "ids 668 50256 <|endoftext|>\n",
      "ids 669 50256 <|endoftext|>\n",
      "ids 670 50256 <|endoftext|>\n",
      "ids 671 50256 <|endoftext|>\n",
      "ids 672 50256 <|endoftext|>\n",
      "ids 673 50256 <|endoftext|>\n",
      "ids 674 50256 <|endoftext|>\n",
      "ids 675 50256 <|endoftext|>\n",
      "ids 676 50256 <|endoftext|>\n",
      "ids 677 50256 <|endoftext|>\n",
      "ids 678 50256 <|endoftext|>\n",
      "ids 679 50256 <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "x = tokenized_train_dataset[100]\n",
    "print(tokenizer.decode(x['input_ids']))\n",
    "print(len(x['labels']))\n",
    "# print(tokenizer.decode([max(32,i) for i in x['labels']]))\n",
    "it = 230\n",
    "x=tokenized_train_dataset[it]\n",
    "# input_ids = []\n",
    "# for i in x[\"input_ids\"]:\n",
    "#     if i == -100 or i == 50256:\n",
    "#         break\n",
    "#     input_ids.append(i)\n",
    "# labels = []\n",
    "# for i in x[\"labels\"]:\n",
    "#     if i == 50256:\n",
    "#         break\n",
    "#     if i == -100:\n",
    "#         continue\n",
    "#     labels.append(i)\n",
    "#     print(input_ids)\n",
    "#     print(\"lens\", len(input_ids), len(labels))\n",
    "for i in range(len(x[\"labels\"])):\n",
    "    print(\"ids\", i, x[\"input_ids\"][i], tokenizer.decode(x[\"input_ids\"][i]))\n",
    "    if x[\"labels\"][i] == -100:\n",
    "        continue\n",
    "    print(\"labels\", i, x[\"labels\"][i], tokenizer.decode(x[\"labels\"][i]))\n",
    "# for i in x[\"labels\"]:\n",
    "#     try:\n",
    "#         print(tokenizer.decode([i]))\n",
    "#     except:\n",
    "#         if i == -100:\n",
    "#             print(\"eos\")\n",
    "#         else:\n",
    "#             print(\"err\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d281795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90d1a22b92a4d1b8fc5711f2316ff0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "tokenized_train_dataset = load_from_disk('data/random_func_array1d_arithmetic_train_tokenized_v1.dataset')\n",
    "tokenized_test_dataset = load_from_disk('data/random_func_array1d_arithmetic_test_tokenized_v1.dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4b1d027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{input [-9 24 9 1] output 22} {input [7 -12 3 5 -1] output 0} {input [-6 -19 -10] output 7} {input [8 2 -3 15 12 -8] output 11} {input [19 6 2 -1 18 -29] output 8} {input [-4 -6 8 3 1 -6 22] output -14} {input [-1 0 7 20 -3 0] output 20} {input [-19 5] output 0} {input [6 -1 6 -4 5 17 15] output 2} {input [11 -12 11] output 15} {input [-8 3 3 2 -8 0] output 7} {input [4 -27 4 2 0] output 0} {input [2 -6 -15 -8 -17 6 12] output -5} {input [3 -6 10 -2] output 4} {input [11 -25 -2 0 -1] output 4} {input [-4 6] output 0} {input [-24 -4] output 0} {input [8 2 -2 -3] output 7} {input [-14 0 -2 4 -1 24] output 24} {input [11 10 -4 -5 -2 5 -8] output 1} {input [-4 3 6] output 7} {input [14 6 -4 -2 -23 -3 3 24] output 31} {input [-2 2 -23 -4 8 -2 11 -5] output 3} {input [-18 7 10 -2 11] output -7} {input [-2 24 -7] output -10} {input [-3 -8 -6] output 7} {input [9 -15 -9 5] output 7} {input [34 9 11 4 0] output 23} {input [3 5] output 0} {input [2 -6 18 -7 -4 -5 15 8] output 11} {input [-8 -6 33 9 0 -13 -9 -11] output 31} {input [-1 -3] output 0} {input [-7 -8] output 0} {input [16 6] output 9} {input [-1 0 5 -10 -7 3 3 3] output 7} {input [-1 10] output -3} {input [0 -3 3 9 2 -3 5 -3] output 5} {input [2 34 -6 1] output 34} {input [-8 -6 -1 -8] output 7} {input [6 37 5 3 6 -11 5] output -30}] def foo(arr):\n",
      " if len(arr) == 1:\n",
      " return max([arr[0], 7])\n",
      " else:\n",
      " if len(arr)!= 4:\n",
      " return max([arr[0], 7]) - foo(arr[1:])\n",
      " else:\n",
      " return foo(arr[1:])\n",
      " <|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "680\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&def foo(arr):\n",
      " if len(arr) == 1:\n",
      " return max([arr[0], 7])\n",
      " else:\n",
      " if len(arr)!= 4:\n",
      " return max([arr[0], 7]) - foo(arr[1:])\n",
      " else:\n",
      " return foo(arr[1:])\n",
      " <|endoftext|>&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n"
     ]
    }
   ],
   "source": [
    "i=5\n",
    "print(tokenizer.decode(tokenized_test_dataset[i]['input_ids']))\n",
    "print(len(tokenized_test_dataset[i]['labels']))\n",
    "print(tokenizer.decode([max(i,x) for x in tokenized_test_dataset[i]['labels']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17bead2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [\n",
      "1 {\n",
      "2 input\n",
      "3  [\n",
      "4 1\n",
      "5  6\n",
      "6  -\n",
      "7 2\n",
      "8  1\n",
      "9  8\n",
      "10 ]\n",
      "11  output\n",
      "12  1\n",
      "13 }\n",
      "14  {\n",
      "15 input\n",
      "16  [\n",
      "17 0\n",
      "18  3\n",
      "19  -\n",
      "20 10\n",
      "21 ]\n",
      "22  output\n",
      "23  0\n",
      "24 }\n",
      "25  {\n",
      "26 input\n",
      "27  [\n",
      "28 21\n",
      "29  -\n",
      "30 17\n",
      "31  1\n",
      "32 ]\n",
      "33  output\n",
      "34  21\n",
      "35 }\n",
      "36  {\n",
      "37 input\n",
      "38  [\n",
      "39 4\n",
      "40  -\n",
      "41 1\n",
      "42 ]\n",
      "43  output\n",
      "44  4\n",
      "45 }\n",
      "46  {\n",
      "47 input\n",
      "48  [-\n",
      "49 7\n",
      "50  -\n",
      "51 9\n",
      "52  -\n",
      "53 4\n",
      "54  -\n",
      "55 2\n",
      "56  3\n",
      "57 ]\n",
      "58  output\n",
      "59  -\n",
      "60 7\n",
      "61 }\n",
      "62  {\n",
      "63 input\n",
      "64  [-\n",
      "65 9\n",
      "66  2\n",
      "67  -\n",
      "68 6\n",
      "69  -\n",
      "70 15\n",
      "71  14\n",
      "72  10\n",
      "73  -\n",
      "74 1\n",
      "75 ]\n",
      "76  output\n",
      "77  -\n",
      "78 9\n",
      "79 }\n",
      "80  {\n",
      "81 input\n",
      "82  [-\n",
      "83 10\n",
      "84  4\n",
      "85  4\n",
      "86  -\n",
      "87 1\n",
      "88  17\n",
      "89  11\n",
      "90 ]\n",
      "91  output\n",
      "92  -\n",
      "93 10\n",
      "94 }\n",
      "95  {\n",
      "96 input\n",
      "97  [-\n",
      "98 6\n",
      "99  -\n",
      "100 32\n",
      "101  -\n",
      "102 5\n",
      "103  6\n",
      "104 ]\n",
      "105  output\n",
      "106  -\n",
      "107 6\n",
      "108 }\n",
      "109  {\n",
      "110 input\n",
      "111  [-\n",
      "112 4\n",
      "113  -\n",
      "114 8\n",
      "115  8\n",
      "116 ]\n",
      "117  output\n",
      "118  -\n",
      "119 4\n",
      "120 }\n",
      "121  {\n",
      "122 input\n",
      "123  [\n",
      "124 16\n",
      "125  -\n",
      "126 2\n",
      "127  3\n",
      "128  0\n",
      "129 ]\n",
      "130  output\n",
      "131  16\n",
      "132 }\n",
      "133  {\n",
      "134 input\n",
      "135  [\n",
      "136 6\n",
      "137  -\n",
      "138 2\n",
      "139  1\n",
      "140  -\n",
      "141 4\n",
      "142  2\n",
      "143 ]\n",
      "144  output\n",
      "145  6\n",
      "146 }\n",
      "147  {\n",
      "148 input\n",
      "149  [-\n",
      "150 16\n",
      "151  7\n",
      "152  -\n",
      "153 6\n",
      "154 ]\n",
      "155  output\n",
      "156  -\n",
      "157 16\n",
      "158 }\n",
      "159  {\n",
      "160 input\n",
      "161  [\n",
      "162 1\n",
      "163  -\n",
      "164 7\n",
      "165  -\n",
      "166 3\n",
      "167  -\n",
      "168 22\n",
      "169  0\n",
      "170 ]\n",
      "171  output\n",
      "172  1\n",
      "173 }\n",
      "174  {\n",
      "175 input\n",
      "176  [\n",
      "177 3\n",
      "178  -\n",
      "179 10\n",
      "180  0\n",
      "181  2\n",
      "182 ]\n",
      "183  output\n",
      "184  3\n",
      "185 }\n",
      "186  {\n",
      "187 input\n",
      "188  [\n",
      "189 5\n",
      "190  0\n",
      "191  -\n",
      "192 27\n",
      "193  4\n",
      "194  26\n",
      "195  0\n",
      "196  9\n",
      "197  0\n",
      "198 ]\n",
      "199  output\n",
      "200  5\n",
      "201 }\n",
      "202  {\n",
      "203 input\n",
      "204  [\n",
      "205 11\n",
      "206  8\n",
      "207  4\n",
      "208  0\n",
      "209  2\n",
      "210 ]\n",
      "211  output\n",
      "212  11\n",
      "213 }\n",
      "214  {\n",
      "215 input\n",
      "216  [\n",
      "217 2\n",
      "218  -\n",
      "219 6\n",
      "220  -\n",
      "221 9\n",
      "222 ]\n",
      "223  output\n",
      "224  2\n",
      "225 }\n",
      "226  {\n",
      "227 input\n",
      "228  [\n",
      "229 10\n",
      "230  2\n",
      "231  23\n",
      "232  1\n",
      "233 ]\n",
      "234  output\n",
      "235  10\n",
      "236 }\n",
      "237  {\n",
      "238 input\n",
      "239  [-\n",
      "240 8\n",
      "241  -\n",
      "242 7\n",
      "243  5\n",
      "244  -\n",
      "245 2\n",
      "246  1\n",
      "247 ]\n",
      "248  output\n",
      "249  -\n",
      "250 8\n",
      "251 }\n",
      "252  {\n",
      "253 input\n",
      "254  [-\n",
      "255 1\n",
      "256  4\n",
      "257  9\n",
      "258  43\n",
      "259  4\n",
      "260  -\n",
      "261 10\n",
      "262  -\n",
      "263 7\n",
      "264  2\n",
      "265 ]\n",
      "266  output\n",
      "267  -\n",
      "268 1\n",
      "269 }\n",
      "270  {\n",
      "271 input\n",
      "272  [-\n",
      "273 5\n",
      "274  11\n",
      "275 ]\n",
      "276  output\n",
      "277  -\n",
      "278 5\n",
      "279 }\n",
      "280  {\n",
      "281 input\n",
      "282  [\n",
      "283 0\n",
      "284  4\n",
      "285  -\n",
      "286 3\n",
      "287  -\n",
      "288 2\n",
      "289  -\n",
      "290 5\n",
      "291  -\n",
      "292 6\n",
      "293  -\n",
      "294 6\n",
      "295  3\n",
      "296 ]\n",
      "297  output\n",
      "298  0\n",
      "299 }\n",
      "300  {\n",
      "301 input\n",
      "302  [\n",
      "303 6\n",
      "304  6\n",
      "305  -\n",
      "306 1\n",
      "307 ]\n",
      "308  output\n",
      "309  6\n",
      "310 }\n",
      "311  {\n",
      "312 input\n",
      "313  [\n",
      "314 12\n",
      "315  -\n",
      "316 10\n",
      "317  2\n",
      "318  5\n",
      "319  4\n",
      "320  0\n",
      "321  11\n",
      "322  16\n",
      "323 ]\n",
      "324  output\n",
      "325  12\n",
      "326 }\n",
      "327  {\n",
      "328 input\n",
      "329  [-\n",
      "330 18\n",
      "331  31\n",
      "332 ]\n",
      "333  output\n",
      "334  -\n",
      "335 18\n",
      "336 }\n",
      "337  {\n",
      "338 input\n",
      "339  [\n",
      "340 35\n",
      "341  2\n",
      "342  5\n",
      "343  11\n",
      "344  7\n",
      "345  3\n",
      "346  -\n",
      "347 20\n",
      "348 ]\n",
      "349  output\n",
      "350  35\n",
      "351 }\n",
      "352  {\n",
      "353 input\n",
      "354  [-\n",
      "355 11\n",
      "356  7\n",
      "357  11\n",
      "358 ]\n",
      "359  output\n",
      "360  -\n",
      "361 11\n",
      "362 }\n",
      "363  {\n",
      "364 input\n",
      "365  [\n",
      "366 0\n",
      "367  -\n",
      "368 9\n",
      "369  26\n",
      "370  2\n",
      "371  0\n",
      "372  -\n",
      "373 5\n",
      "374  -\n",
      "375 4\n",
      "376 ]\n",
      "377  output\n",
      "378  0\n",
      "379 }\n",
      "380  {\n",
      "381 input\n",
      "382  [-\n",
      "383 5\n",
      "384  25\n",
      "385 ]\n",
      "386  output\n",
      "387  -\n",
      "388 5\n",
      "389 }\n",
      "390  {\n",
      "391 input\n",
      "392  [-\n",
      "393 8\n",
      "394  11\n",
      "395  11\n",
      "396  0\n",
      "397  -\n",
      "398 10\n",
      "399  -\n",
      "400 13\n",
      "401  -\n",
      "402 16\n",
      "403  3\n",
      "404 ]\n",
      "405  output\n",
      "406  -\n",
      "407 8\n",
      "408 }\n",
      "409  {\n",
      "410 input\n",
      "411  [\n",
      "412 3\n",
      "413  -\n",
      "414 9\n",
      "415  2\n",
      "416  3\n",
      "417  4\n",
      "418 ]\n",
      "419  output\n",
      "420  3\n",
      "421 }\n",
      "422  {\n",
      "423 input\n",
      "424  [-\n",
      "425 6\n",
      "426  -\n",
      "427 3\n",
      "428  18\n",
      "429  15\n",
      "430  -\n",
      "431 31\n",
      "432  -\n",
      "433 9\n",
      "434  3\n",
      "435  0\n",
      "436 ]\n",
      "437  output\n",
      "438  -\n",
      "439 6\n",
      "440 }\n",
      "441  {\n",
      "442 input\n",
      "443  [\n",
      "444 9\n",
      "445  -\n",
      "446 1\n",
      "447  8\n",
      "448  0\n",
      "449 ]\n",
      "450  output\n",
      "451  9\n",
      "452 }\n",
      "453  {\n",
      "454 input\n",
      "455  [-\n",
      "456 24\n",
      "457  0\n",
      "458  0\n",
      "459  9\n",
      "460  9\n",
      "461  -\n",
      "462 34\n",
      "463  3\n",
      "464 ]\n",
      "465  output\n",
      "466  -\n",
      "467 24\n",
      "468 }\n",
      "469  {\n",
      "470 input\n",
      "471  [\n",
      "472 2\n",
      "473  -\n",
      "474 4\n",
      "475  -\n",
      "476 4\n",
      "477 ]\n",
      "478  output\n",
      "479  2\n",
      "480 }\n",
      "481  {\n",
      "482 input\n",
      "483  [-\n",
      "484 10\n",
      "485  -\n",
      "486 4\n",
      "487  -\n",
      "488 1\n",
      "489 ]\n",
      "490  output\n",
      "491  -\n",
      "492 10\n",
      "493 }\n",
      "494  {\n",
      "495 input\n",
      "496  [-\n",
      "497 8\n",
      "498  4\n",
      "499  19\n",
      "500  2\n",
      "501  11\n",
      "502  4\n",
      "503  -\n",
      "504 17\n",
      "505  -\n",
      "506 12\n",
      "507 ]\n",
      "508  output\n",
      "509  -\n",
      "510 8\n",
      "511 }\n",
      "512  {\n",
      "513 input\n",
      "514  [-\n",
      "515 2\n",
      "516  3\n",
      "517  -\n",
      "518 10\n",
      "519  -\n",
      "520 3\n",
      "521  -\n",
      "522 13\n",
      "523  16\n",
      "524 ]\n",
      "525  output\n",
      "526  -\n",
      "527 2\n",
      "528 }\n",
      "529  {\n",
      "530 input\n",
      "531  [-\n",
      "532 8\n",
      "533  0\n",
      "534  2\n",
      "535  -\n",
      "536 34\n",
      "537  -\n",
      "538 15\n",
      "539  -\n",
      "540 3\n",
      "541 ]\n",
      "542  output\n",
      "543  -\n",
      "544 8\n",
      "545 }\n",
      "546  {\n",
      "547 input\n",
      "548  [\n",
      "549 17\n",
      "550  6\n",
      "551  15\n",
      "552  -\n",
      "553 13\n",
      "554  -\n",
      "555 5\n",
      "556  -\n",
      "557 16\n",
      "558  -\n",
      "559 5\n",
      "560  12\n",
      "561 ]\n",
      "562  output\n",
      "563  17\n",
      "564 }\n",
      "565 ]\n",
      "566  def\n",
      "567  foo\n",
      "568 (\n",
      "569 arr\n",
      "570 ):\n",
      "571 \n",
      "\n",
      "572  if\n",
      "573  len\n",
      "574 (\n",
      "575 arr\n",
      "576 )\n",
      "577  ==\n",
      "578  1\n",
      "579 :\n",
      "580 \n",
      "\n",
      "581  return\n",
      "582  arr\n",
      "583 [\n",
      "584 0\n",
      "585 ]\n",
      "586 \n",
      "\n",
      "587  else\n",
      "588 :\n",
      "589 \n",
      "\n",
      "590  return\n",
      "591  arr\n",
      "592 [\n",
      "593 0\n",
      "594 ]\n",
      "595 \n",
      "\n",
      "596  \n",
      "597 <|endoftext|>\n",
      "598 <|endoftext|>\n",
      "599 <|endoftext|>\n",
      "600 <|endoftext|>\n",
      "601 <|endoftext|>\n",
      "602 <|endoftext|>\n",
      "603 <|endoftext|>\n",
      "604 <|endoftext|>\n",
      "605 <|endoftext|>\n",
      "606 <|endoftext|>\n",
      "607 <|endoftext|>\n",
      "608 <|endoftext|>\n",
      "609 <|endoftext|>\n",
      "610 <|endoftext|>\n",
      "611 <|endoftext|>\n",
      "612 <|endoftext|>\n",
      "613 <|endoftext|>\n",
      "614 <|endoftext|>\n",
      "615 <|endoftext|>\n",
      "616 <|endoftext|>\n",
      "617 <|endoftext|>\n",
      "618 <|endoftext|>\n",
      "619 <|endoftext|>\n",
      "620 <|endoftext|>\n",
      "621 <|endoftext|>\n",
      "622 <|endoftext|>\n",
      "623 <|endoftext|>\n",
      "624 <|endoftext|>\n",
      "625 <|endoftext|>\n",
      "626 <|endoftext|>\n",
      "627 <|endoftext|>\n",
      "628 <|endoftext|>\n",
      "629 <|endoftext|>\n",
      "630 <|endoftext|>\n",
      "631 <|endoftext|>\n",
      "632 <|endoftext|>\n",
      "633 <|endoftext|>\n",
      "634 <|endoftext|>\n",
      "635 <|endoftext|>\n",
      "636 <|endoftext|>\n",
      "637 <|endoftext|>\n",
      "638 <|endoftext|>\n",
      "639 <|endoftext|>\n",
      "640 <|endoftext|>\n",
      "641 <|endoftext|>\n",
      "642 <|endoftext|>\n",
      "643 <|endoftext|>\n",
      "644 <|endoftext|>\n",
      "645 <|endoftext|>\n",
      "646 <|endoftext|>\n",
      "647 <|endoftext|>\n",
      "648 <|endoftext|>\n",
      "649 <|endoftext|>\n",
      "650 <|endoftext|>\n",
      "651 <|endoftext|>\n",
      "652 <|endoftext|>\n",
      "653 <|endoftext|>\n",
      "654 <|endoftext|>\n",
      "655 <|endoftext|>\n",
      "656 <|endoftext|>\n",
      "657 <|endoftext|>\n",
      "658 <|endoftext|>\n",
      "659 <|endoftext|>\n",
      "660 <|endoftext|>\n",
      "661 <|endoftext|>\n",
      "662 <|endoftext|>\n",
      "663 <|endoftext|>\n",
      "664 <|endoftext|>\n",
      "665 <|endoftext|>\n",
      "666 <|endoftext|>\n",
      "667 <|endoftext|>\n",
      "668 <|endoftext|>\n",
      "669 <|endoftext|>\n",
      "670 <|endoftext|>\n",
      "671 <|endoftext|>\n",
      "672 <|endoftext|>\n",
      "673 <|endoftext|>\n",
      "674 <|endoftext|>\n",
      "675 <|endoftext|>\n",
      "676 <|endoftext|>\n",
      "677 <|endoftext|>\n",
      "678 <|endoftext|>\n",
      "679 <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenized_test_dataset[0]['input_ids']\n",
    "for i in range(MAX_LENGTH):\n",
    "    print(i, tokenizer.decode([input_ids[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "541eea41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcwave/anaconda3/envs/torch200/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "import torch\n",
    "import torch.nn.init as init\n",
    "from transformers import AutoModel\n",
    "\n",
    "def initialize_weights(model, init_type='xavier'):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            if init_type == 'xavier':\n",
    "                init.xavier_uniform_(module.weight)\n",
    "            elif init_type == 'he':\n",
    "                init.kaiming_uniform_(module.weight, nonlinearity='relu')\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.fill_(0)\n",
    "\n",
    "# Load the tokenizer and model\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"xhyi/PT_GPTNEO350_ATG\") #\"EleutherAI/gpt-neo-1.3B\")\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"xhyi/PT_GPTNEO350_ATG\") #\"EleutherAI/gpt-neo-1.3B\") #\n",
    "\n",
    "# Initialize weights\n",
    "initialize_weights(model, init_type='he')  # Or 'he' for He initialization\n",
    "\n",
    "\n",
    "# # Tokenize and preprocess the dataset\n",
    "# def preprocess_function(examples):\n",
    "#     inputs = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=1024)\n",
    "#     inputs[\"labels\"] = inputs.input_ids.copy()\n",
    "#     return inputs\n",
    "\n",
    "# tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "# tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65a6aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcwave/anaconda3/envs/torch200/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxiaoxinyin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mcwave/code/automath/autocode/wandb/run-20240331_164434-zhkvya1s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xiaoxinyin/huggingface/runs/zhkvya1s' target=\"_blank\">unique-morning-265</a></strong> to <a href='https://wandb.ai/xiaoxinyin/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xiaoxinyin/huggingface' target=\"_blank\">https://wandb.ai/xiaoxinyin/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xiaoxinyin/huggingface/runs/zhkvya1s' target=\"_blank\">https://wandb.ai/xiaoxinyin/huggingface/runs/zhkvya1s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326892' max='791670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326892/791670 90:13:19 < 128:16:45, 1.01 it/s, Epoch 2.06/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.162700</td>\n",
       "      <td>0.097327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.089200</td>\n",
       "      <td>0.083678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.074212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.069186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.063345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.060568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.058540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160000</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.057395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180000</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.055768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200000</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>0.054824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220000</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.053568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240000</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>0.052617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260000</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.052288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.051656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300000</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.050672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320000</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>0.050538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./data/results-gptneo350m\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    save_steps=20000,\n",
    "    eval_steps=20000,\n",
    "    logging_steps=20000,\n",
    "    logging_dir=\"./data/logs\",\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f2ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(model, 'data/results/gptneo350m-random_func_array1d_arithmetic-v1-417600.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74617ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.load('data/results/gptneo350m-random_func_array1d_arithmetic-v1-417600.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = tokenized_test_dataset[0]\n",
    "label = example['labels']\n",
    "input_ids = list(example['input_ids'])\n",
    "\n",
    "i = 0\n",
    "while label[i] == -100:\n",
    "    i += 1\n",
    "instruction_len = i\n",
    "\n",
    "for i in range(instruction_len, len(input_ids)):\n",
    "    input_ids[i] = 50256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b391549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18607ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "example = tokenized_test_dataset[30]\n",
    "label = example['labels']\n",
    "input_ids = list(example['input_ids'])\n",
    "\n",
    "i = 0\n",
    "while label[i] == -100:\n",
    "    i += 1\n",
    "instruction_len = i + 5\n",
    "\n",
    "for i in range(instruction_len, len(input_ids)):\n",
    "    input_ids[i] = 50256\n",
    "\n",
    "print(example['instruction'])\n",
    "print(example['response'])\n",
    "\n",
    "START_IDX = instruction_len\n",
    "\n",
    "inputs_ids = torch.tensor(input_ids)\n",
    "attention_mask = torch.ones(MAX_LENGTH)\n",
    "idx = START_IDX\n",
    "\n",
    "while idx < len(input_ids):\n",
    "    #print(\"input_ids:\", tokenizer.decode(inputs_ids))\n",
    "    #print(\"inputs_embeds:\", example['inputs_embeds'][758:770])\n",
    "    #print(\"attention_mask:\", example['attention_mask'][768:780])\n",
    "    #print(\"labels:\", tokenizer.decode(example['labels'][768:780]))\n",
    "    outputs = model(input_ids=torch.unsqueeze(inputs_ids, 0).to('cuda:0'),\n",
    "                    attention_mask=torch.unsqueeze(attention_mask, 0).to('cuda:0'))\n",
    "    #\n",
    "    logits = outputs.logits\n",
    "    #print(\"logits:\", logits[:, idx, :])\n",
    "    predicted_token_id = torch.argmax(logits[:, idx, :], dim=-1)\n",
    "    if predicted_token_id == eos_encoded:\n",
    "        break\n",
    "    # Convert the token ID to the actual token\n",
    "    predicted_token = tokenizer.decode(predicted_token_id)\n",
    "    print(idx, predicted_token)\n",
    "    idx += 1\n",
    "    #if idx > START_IDX+2:\n",
    "    inputs_ids[idx] = predicted_token_id.detach().cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbde590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing \n",
    "\n",
    "a = [1,2,-3,4,5]\n",
    "\n",
    "def squared_sum(arr):\n",
    "    return sum([x*x for x in arr])\n",
    "\n",
    "def abs_sum(arr):\n",
    "    return sum([abs(x) for x in arr])\n",
    "\n",
    "def sum2(arr):\n",
    "    return 2*sum(arr)\n",
    "\n",
    "def sum5(arr):\n",
    "    return 5*sum(arr)\n",
    "\n",
    "def sum_plus_len(arr):\n",
    "    return sum(arr) + len(arr)\n",
    "\n",
    "def sum_plus_2len(arr):\n",
    "    return sum(arr) + 2*len(arr)\n",
    "\n",
    "def sum_minus_len(arr):\n",
    "    return sum(arr) - len(arr)\n",
    "\n",
    "def sum_positive(arr):\n",
    "    return sum([x for x in arr if x > 0])\n",
    "\n",
    "def sum_negative(arr):\n",
    "    return sum([x for x in arr if x < 0])\n",
    "\n",
    "def sum_greater_than_3(arr):\n",
    "    return sum([x for x in arr if x > 3])\n",
    "\n",
    "def sum_mod_3(arr):\n",
    "    return sum([x%3 for x in arr])\n",
    "\n",
    "def interleaving_substract(arr):\n",
    "    if len(arr) == 1:\n",
    "        return arr[0]\n",
    "    else:\n",
    "        return arr[0] - interleaving_substract(arr[1:])\n",
    "    \n",
    "def product(arr):\n",
    "    if len(arr) == 1:\n",
    "        return arr[0]\n",
    "    else:\n",
    "        return arr[0] * product(arr[1:])\n",
    "    \n",
    "def product_plus1(arr):\n",
    "    if len(arr) == 1:\n",
    "        return arr[0] + 1\n",
    "    else:\n",
    "        return (arr[0] + 1) * product(arr[1:])\n",
    "    \n",
    "def product_plus2(arr):\n",
    "    if len(arr) == 1:\n",
    "        return arr[0] + 2\n",
    "    else:\n",
    "        return (arr[0] + 2) * product(arr[1:])\n",
    "    \n",
    "def first(arr):\n",
    "    return arr[0]\n",
    "\n",
    "def last(arr):\n",
    "    return arr[-1]\n",
    "\n",
    "def second(arr):\n",
    "    return arr[1]\n",
    "\n",
    "def third(arr):\n",
    "    return arr[2]\n",
    "\n",
    "def second2last(arr):\n",
    "    return arr[-2]\n",
    "\n",
    "def third2last(arr):\n",
    "    return arr[-3]\n",
    "    \n",
    "test_functions = [sum, max, min, squared_sum, abs_sum, sum2, sum5, sum_plus_len, sum_plus_2len, \n",
    "                  sum_minus_len, sum_positive, sum_negative, sum_greater_than_3, sum_mod_3, \n",
    "                  interleaving_substract, product, product_plus1, product_plus2, first, last]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d7edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def format_code(code):\n",
    "    INDENT = \"    \"\n",
    "    lines = [l.strip() for l in code.split('\\n')]\n",
    "    lines = [l for l in lines if len(l) > 2]\n",
    "    formatted = lines[0] + '\\n'\n",
    "    current_indent = \"\"\n",
    "    for i in range(1, len(lines)):\n",
    "        if lines[i-1].endswith(':'):\n",
    "            current_indent += INDENT\n",
    "        else:\n",
    "            current_indent = current_indent[0:-len(INDENT)]\n",
    "        formatted += current_indent + lines[i] + '\\n'\n",
    "    return formatted\n",
    "\n",
    "def generate_random_array():\n",
    "    length = random.randint(2, 8)  # Randomly choose the length of the array\n",
    "    # Generate the array with absolute values following an exponential distribution\n",
    "    array = [(-1)**random.randint(0, 1) * round(np.random.exponential(scale=8.0)) for _ in range(length)]\n",
    "    return array\n",
    "\n",
    "def create_test_input(foo, num_random_array=40):\n",
    "    datum = {}\n",
    "    #\n",
    "    datum['random_code'] = \"def foo(arr):\\n\"\n",
    "    results = []\n",
    "    random_arrays = []\n",
    "    random_results = []\n",
    "    for j in range(num_random_array):\n",
    "        random_array = generate_random_array()\n",
    "        random_arrays.append(random_array)\n",
    "        try:\n",
    "            result = foo(random_array)\n",
    "        except Exception as e:\n",
    "            result = type(e).__name__\n",
    "        random_results.append(result)\n",
    "        results.append({\"input\":str(random_array), \"output\":result})\n",
    "    datum['results'] = results\n",
    "    instruction = str(datum[\"results\"]).replace(\"\\'\", '').replace('ZeroDivisionError', 'error').replace(':', '').replace(',', '')\n",
    "    response = datum[\"random_code\"]\n",
    "    for i in range(10):\n",
    "        response = response.replace('  ', ' ')\n",
    "    return instruction, response, random_arrays, random_results\n",
    "\n",
    "def get_input_ids(foo, num_random_array=40):\n",
    "    instruction, response, random_arrays, random_results = create_test_input(foo, num_random_array=num_random_array)\n",
    "    #print(instruction)\n",
    "    tokenized_data = tokenizer(instruction + \" \" + response, truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)\n",
    "    return tokenized_data, random_arrays, random_results\n",
    "\n",
    "def check_infer_function(f, verbose=False):\n",
    "    print(\"\\nFUNCTION:\", f.__name__)\n",
    "    tokenized_data, random_arrays, random_results = get_input_ids(f)\n",
    "    input_ids = tokenized_data['input_ids']\n",
    "    #print(input_ids)\n",
    "    #tokenizer.decode(input_ids)\n",
    "    instruction_len = len([x for x in input_ids if x < 50256])\n",
    "    START_IDX = instruction_len\n",
    "    inputs_ids = torch.tensor(input_ids)\n",
    "    attention_mask = torch.ones(MAX_LENGTH)\n",
    "    idx = START_IDX\n",
    "    #\n",
    "    try:\n",
    "        output = \"def foo(arr):\\n\"\n",
    "        while idx < len(input_ids):\n",
    "            #print(\"input_ids:\", tokenizer.decode(inputs_ids))\n",
    "            #print(\"inputs_embeds:\", example['inputs_embeds'][758:770])\n",
    "            #print(\"attention_mask:\", example['attention_mask'][768:780])\n",
    "            #print(\"labels:\", tokenizer.decode(example['labels'][768:780]))\n",
    "            outputs = model(input_ids=torch.unsqueeze(inputs_ids, 0).to('cuda:0'),\n",
    "                            attention_mask=torch.unsqueeze(attention_mask, 0).to('cuda:0'))\n",
    "            #\n",
    "            logits = outputs.logits\n",
    "            #print(\"logits:\", logits[:, idx, :])\n",
    "            predicted_token_id = torch.argmax(logits[:, idx, :], dim=-1)\n",
    "            if predicted_token_id == eos_encoded:\n",
    "                break\n",
    "            # Convert the token ID to the actual token\n",
    "            predicted_token = tokenizer.decode(predicted_token_id)\n",
    "            output += predicted_token\n",
    "            #print(idx, predicted_token)\n",
    "            idx += 1\n",
    "            inputs_ids[idx] = predicted_token_id.detach().cpu().numpy()[0]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "    #\n",
    "    inferred_code = format_code(output)\n",
    "    print(inferred_code)\n",
    "    exec(inferred_code, globals())\n",
    "    #\n",
    "    count_equal = 0\n",
    "    for i in range(len(random_arrays)):\n",
    "        try:\n",
    "            result = foo(random_arrays[i])\n",
    "        except Exception as e:\n",
    "            result = type(e).__name__\n",
    "        if verbose:\n",
    "            print(\"Random array:\", random_arrays[i])\n",
    "            print(\"Expected result:\", random_results[i])\n",
    "            print(\"Actual result:  \", result)\n",
    "        if random_results[i] == result:\n",
    "            count_equal += 1\n",
    "    #\n",
    "    print(count_equal, '/', len(random_arrays))\n",
    "\n",
    "for f in test_functions:\n",
    "    check_infer_function(f)\n",
    "\n",
    "#check_infer_function(min, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18ebdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def foo(arr):\n",
    "#         if len(arr) == 1:\n",
    "#             return arr[0]\n",
    "#         else:\n",
    "#             return max([arr[0], foo(arr[1:])])\n",
    "\n",
    "del foo\n",
    "foo([8, 11, 13, -5, 6, -13, -8, 2, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f309c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(inferred_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7164132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch200",
   "language": "python",
   "name": "torch200"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
